{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "4Kpw8dTp_EI6",
        "xXNVidVPsiT0",
        "SjpHb4Cnfdrc",
        "R5Pq5RYzfpfK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import and Install"
      ],
      "metadata": {
        "id": "4Kpw8dTp_EI6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utVzGB5n-XVh",
        "outputId": "56c2bd81-3272-4775-dff5-7be5e9a2e9cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall the current version of pandas\n",
        "!pip uninstall -y pandas\n",
        "\n",
        "# Install pandas version 1.3.5\n",
        "!pip install pandas==1.3.5\n",
        "\n",
        "# Import pandas and print the version to confirm the installation\n",
        "import pandas as pd\n",
        "print(f\"Installed pandas version: {pd.__version__}\")\n",
        "\n",
        "!pip install natsort plotly matplotlib scikit-learn seaborn imageio wandb google-cloud-bigquery\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lob6Htop-ZDm",
        "outputId": "e7b34526-54b8-440a-80e6-37222a04d92f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pandas 1.3.5\n",
            "Uninstalling pandas-1.3.5:\n",
            "  Successfully uninstalled pandas-1.3.5\n",
            "Collecting pandas==1.3.5\n",
            "  Using cached pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.3.5) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.3.5) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.3.5) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.5) (1.16.0)\n",
            "Installing collected packages: pandas\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.11.1 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.3.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 1.3.5 which is incompatible.\n",
            "plotnine 0.12.4 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "statsmodels 0.14.2 requires pandas!=2.1.0,>=1.4, but you have pandas 1.3.5 which is incompatible.\n",
            "xarray 2023.7.0 requires pandas>=1.4, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.3.5\n",
            "Installed pandas version: 1.3.5\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (8.4.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.4)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (3.21.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.3.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.10.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.16.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.27.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.7.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.63.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (1.5.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import logging\n",
        "from IPython.display import display, HTML\n",
        "import sys\n",
        "import os\n",
        "from joblib import dump\n",
        "from sklearn import tree\n",
        "import google.colab.data_table\n",
        "import importlib.util\n",
        "import time\n",
        "import gc\n",
        "import glob\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5lq5qPLL-aa8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install /content/drive/My\\ Drive/ML_Nuclear_Data/nucml-1.0.5-dev.1/nucml-1.0.5-dev.1\n",
        "!pip install git+https://github.com/tensorflow/docs\n",
        "!pip install tensorflow xgboost\n",
        "!python -c \"import nucml.configure as config; config.configure('.', 'acedata/', matlab_exe_path='/mnt/c/Program\\ Files/MATLAB/R2019a/bin/matlab.exe')\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpCWiBdp-iQq",
        "outputId": "4d672bc3-ac8a-4baf-e82c-7d80ecfd65da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./drive/My Drive/ML_Nuclear_Data/nucml-1.0.5-dev.1/nucml-1.0.5-dev.1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from nucml==1.0.5.dev1) (8.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nucml==1.0.5.dev1) (1.3.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from nucml==1.0.5.dev1) (5.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from nucml==1.0.5.dev1) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nucml==1.0.5.dev1) (1.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from nucml==1.0.5.dev1) (0.13.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from nucml==1.0.5.dev1) (2.31.6)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from nucml==1.0.5.dev1) (0.17.4)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (from nucml==1.0.5.dev1) (3.21.0)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->nucml==1.0.5.dev1) (2.16.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->nucml==1.0.5.dev1) (2.27.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->nucml==1.0.5.dev1) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->nucml==1.0.5.dev1) (2.7.1)\n",
            "Requirement already satisfied: packaging>=20.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->nucml==1.0.5.dev1) (24.1)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->nucml==1.0.5.dev1) (2.8.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->nucml==1.0.5.dev1) (2.31.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio->nucml==1.0.5.dev1) (1.25.2)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio->nucml==1.0.5.dev1) (9.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nucml==1.0.5.dev1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nucml==1.0.5.dev1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nucml==1.0.5.dev1) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nucml==1.0.5.dev1) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nucml==1.0.5.dev1) (3.1.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas->nucml==1.0.5.dev1) (2023.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->nucml==1.0.5.dev1) (8.5.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nucml==1.0.5.dev1) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nucml==1.0.5.dev1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nucml==1.0.5.dev1) (3.5.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->nucml==1.0.5.dev1) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->nucml==1.0.5.dev1) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->nucml==1.0.5.dev1) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->nucml==1.0.5.dev1) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->nucml==1.0.5.dev1) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->nucml==1.0.5.dev1) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb->nucml==1.0.5.dev1) (6.0.1)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->nucml==1.0.5.dev1) (2.10.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->nucml==1.0.5.dev1) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->nucml==1.0.5.dev1) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->nucml==1.0.5.dev1) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->nucml==1.0.5.dev1) (4.0.11)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery->nucml==1.0.5.dev1) (1.63.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery->nucml==1.0.5.dev1) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery->nucml==1.0.5.dev1) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery->nucml==1.0.5.dev1) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery->nucml==1.0.5.dev1) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery->nucml==1.0.5.dev1) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery->nucml==1.0.5.dev1) (1.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery->nucml==1.0.5.dev1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery->nucml==1.0.5.dev1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery->nucml==1.0.5.dev1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery->nucml==1.0.5.dev1) (2024.7.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->nucml==1.0.5.dev1) (5.0.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery->nucml==1.0.5.dev1) (0.6.0)\n",
            "Building wheels for collected packages: nucml\n",
            "  Building wheel for nucml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nucml: filename=nucml-1.0.5.dev1-py3-none-any.whl size=255178 sha256=bbdbacc0ad9438fe646b8539123446645f3b130726b260bfca75e853e017f444\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/d4/b6/c694cba4d407d574476552aab353f8a7cd263211ebb48723ff\n",
            "Successfully built nucml\n",
            "Installing collected packages: nucml\n",
            "  Attempting uninstall: nucml\n",
            "    Found existing installation: nucml 1.0.5.dev1\n",
            "    Uninstalling nucml-1.0.5.dev1:\n",
            "      Successfully uninstalled nucml-1.0.5.dev1\n",
            "Successfully installed nucml-1.0.5.dev1\n",
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-aiy83acz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-aiy83acz\n",
            "  Resolved https://github.com/tensorflow/docs to commit 773bcc865af5d5a45b405c80faf6fcc3cc510d7d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.7.15.51478) (0.8.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.7.15.51478) (1.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.7.15.51478) (3.1.4)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.7.15.51478) (5.10.4)\n",
            "Requirement already satisfied: protobuf>=3.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.7.15.51478) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.7.15.51478) (6.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->tensorflow-docs==2024.7.15.51478) (2.1.5)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.7.15.51478) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.7.15.51478) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.7.15.51478) (5.7.2)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.7.15.51478) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.7.15.51478) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.7.15.51478) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.7.15.51478) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.7.15.51478) (0.19.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->tensorflow-docs==2024.7.15.51478) (4.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nucml/configure.py\", line 6, in <module>\n",
            "    drive.mount('/content/drive')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\", line 100, in mount\n",
            "    return _mount(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\", line 133, in _mount\n",
            "    _message.blocking_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\", line 173, in blocking_request\n",
            "    request_id = send_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\", line 117, in send_request\n",
            "    instance = ipython.get_kernelapp()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/colab/_ipython.py\", line 28, in get_kernelapp\n",
            "    return get_ipython().kernel.parent\n",
            "AttributeError: 'NoneType' object has no attribute 'kernel'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-run the import script\n",
        "import os\n",
        "import importlib\n",
        "import pkgutil\n",
        "\n",
        "# Ensure Google Drive is mounted\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Base directory for the nucml module\n",
        "base_dir = '/usr/local/lib/python3.10/dist-packages/nucml'\n",
        "\n",
        "# List to keep track of missing modules\n",
        "missing_modules = []\n",
        "\n",
        "# Function to dynamically import all modules in the nucml package\n",
        "def import_all_modules(base_dir, package_name):\n",
        "    for _, module_name, ispkg in pkgutil.walk_packages([base_dir], package_name + \".\"):\n",
        "        if not ispkg:\n",
        "            try:\n",
        "                importlib.import_module(module_name)\n",
        "                print(f\"Imported {module_name}\")\n",
        "            except ModuleNotFoundError as e:\n",
        "                print(f\"Failed to import {module_name}: {e}\")\n",
        "                missing_modules.append(module_name)\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred while importing {module_name}: {e}\")\n",
        "                missing_modules.append(module_name)\n",
        "\n",
        "# Import all modules in the nucml package\n",
        "import_all_modules(base_dir, 'nucml')\n",
        "\n",
        "# Print list of missing modules\n",
        "if missing_modules:\n",
        "    print(\"\\nThe following modules could not be imported:\")\n",
        "    for module in missing_modules:\n",
        "        print(module)\n",
        "else:\n",
        "    print(\"\\nAll modules were imported successfully.\")"
      ],
      "metadata": {
        "id": "Z5ztOHZ1-stT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d59f970-c1c7-4600-e608-039fbf9fede8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Paths set in config.py:\n",
            "ame_dir_path: /content/drive/My Drive/ML_Nuclear_Data/AME/CSV_Files\n",
            "evaluations_path: /content/drive/My Drive/ML_Nuclear_Data/Evaluated_Data\n",
            "ensdf_path: /content/drive/My Drive/ML_Nuclear_Data/ENSDF\n",
            "exfor_path: /content/drive/My Drive/ML_Nuclear_Data/EXFOR/CSV_Files\n",
            "bench_template_path: /content/drive/My Drive/ML_Nuclear_Data/Benchmarks/inputs/templates\n",
            "ace_path: /content/drive/My Drive/ML_Nuclear_Data/acedata\n",
            "matlab_path: /mnt/c/Program Files/MATLAB/R2019a/bin/matlab.exe\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Imported nucml.ace.data_utilities\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Imported nucml.ace.plot\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Imported nucml.ace.plotting_utilities\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Imported nucml.ame.parsing\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Imported nucml.ame.parsing_utilities\n",
            "Imported nucml.config\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Paths set in configure.py:\n",
            "ame_dir_path: /content/drive/My Drive/ML_Nuclear_Data/AME/CSV_Files\n",
            "evaluations_path: /content/drive/My Drive/ML_Nuclear_Data/Evaluated_Data\n",
            "ensdf_path: /content/drive/My Drive/ML_Nuclear_Data/ENSDF\n",
            "exfor_path: /content/drive/My Drive/ML_Nuclear_Data/EXFOR/CSV_Files\n",
            "bench_template_path: /content/drive/My Drive/ML_Nuclear_Data/Benchmarks/inputs/templates\n",
            "ace_path: /content/drive/My Drive/ML_Nuclear_Data/acedata\n",
            "matlab_path: /mnt/c/Program Files/MATLAB/R2019a/bin/matlab.exe\n",
            "Imported nucml.configure\n",
            "Imported nucml.datasets\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Imported nucml.ensdf.data_utilities\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Imported nucml.ensdf.parsing\n",
            "Imported nucml.ensdf.plot\n",
            "Imported nucml.evaluation.data_utilities\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Imported nucml.evaluation.plot\n",
            "Imported nucml.exfor.data_utilities\n",
            "Imported nucml.exfor.parsing\n",
            "Imported nucml.exfor.plot\n",
            "Imported nucml.general_utilities\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Failed to import nucml.model.building_utils: No module named 'wandb.keras'\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Failed to import nucml.model.model_building: No module named 'wandb.keras'\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Imported nucml.model.plot\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Imported nucml.model.training\n",
            "Imported nucml.model.utilities\n",
            "Imported nucml.objects.objects\n",
            "Imported nucml.plot.utilities\n",
            "Imported nucml.processing\n",
            "\n",
            "The following modules could not be imported:\n",
            "nucml.model.building_utils\n",
            "nucml.model.model_building\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the modules for further use if needed\n",
        "import nucml.ace.data_utilities as ace_utils              # pylint: disable=import-error\n",
        "import nucml.evaluation.data_utilities as endf_utils      # pylint: disable=import-error\n",
        "import nucml.datasets as nuc_data                         # pylint: disable=import-error\n",
        "import nucml.model.utilities as model_utils               # pylint: disable=import-error\n",
        "import nucml.plot.utilities as plot_utils                 # pylint: disable=import-error\n",
        "import nucml.general_utilities as gen_utils               # pylint: disable=import-error\n",
        "import nucml.exfor.plot as exfor_plot_utils               # pylint: disable=import-error\n",
        "import nucml.config as config                             # pylint: disable=import-error\n",
        "import nucml.exfor.data_utilities as exfor_utils\n"
      ],
      "metadata": {
        "id": "U_MPK_Wq-6cE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Exfor"
      ],
      "metadata": {
        "id": "TKv09KLgRGKj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p0ZCdFCuHzNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define input parameters\n",
        "log = True                 # If True, the log of the Energy and Cross Section is taken. Defaults to False.\n",
        "low_en = True              # If True, an upper limit in energy is applied given by the max_en argument. Defaults to False.\n",
        "basic = 1                 # Indicates how many features to load. 1 means basic features. Defaults to -1.\n",
        "num = True                 # If True, only numerical and relevant categorical features are loaded. Defaults to False.\n",
        "frac = 0.1                 # Fraction of the dataset for the test set. Defaults to 0.1.\n",
        "mode = \"protons\"          # Dataset to load. Options include neutrons, gammas, and protons. Defaults to \"neutrons\".\n",
        "scaling_type = \"standard\"  # Type of scaler to use for normalizing the dataset. Defaults to \"standard\".\n",
        "scaler_dir = None          # Directory in which to store the trained scaler. Defaults to None.\n",
        "filters = True             # If True, a variety of filters are applied that help discard irregular data. Defaults to False.\n",
        "max_en = 2.0E7             # Maximum energy threshold by which the dataset is filtered. Defaults to 2.0E7.\n",
        "mt_coding = \"one_hot\"      # Method used to process the MT reaction channel codes. Defaults to \"one_hot\".\n",
        "scale_energy = False       # If True, the energy will be normalized along with all other features. Defaults to False.\n",
        "projectile_coding = \"one_hot\"  # Method used to process the type of projectile. Defaults to \"one_hot\".\n",
        "normalize = True           # If True, the data will be normalized. Defaults to True.\n",
        "pedro = True              # Personal settings. Defaults to False.\n",
        "pedro_v2 = False           # Personal settings version 2. Defaults to False.\n",
        "chunk_size = 800000         # To limit RAM usage by reading the data in chunks of this size. Defaults to None.\n",
        "Z_range = None             # If true, filters based on below\n",
        "N_range = None             # Range for values, defaults to none\n",
        "A_range = None\n",
        "filter_Z_A= False\n",
        "# Call the load_exfor function\n",
        "try:\n",
        "    result = nuc_data.load_exfor(\n",
        "        log=log, low_en=low_en, basic=basic, num=num, frac=frac, mode=mode, scaling_type=scaling_type,\n",
        "        scaler_dir=scaler_dir, filters=filters, max_en=max_en, mt_coding=mt_coding, scale_energy=scale_energy,\n",
        "        projectile_coding=projectile_coding, normalize=normalize, pedro=pedro, pedro_v2=pedro_v2, chunk_size=chunk_size\n",
        "    )\n",
        "except TypeError as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    result = None\n",
        "\n",
        "# Print the result\n",
        "if result is not None:\n",
        "    if num:\n",
        "        df, x_train, x_test, y_train, y_test, to_scale, scaler = result\n",
        "\n",
        "        # Determine the size of the validation set to match the test set\n",
        "        val_size = x_test.shape[0]\n",
        "\n",
        "        # Further split the training dataset into training and validation datasets with equal sizes for val and test\n",
        "        x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=val_size, random_state=42)\n",
        "\n",
        "        # Print the shapes of the datasets\n",
        "        print(\"Shapes of the datasets:\")\n",
        "        print(f\"Original Data: {df.shape}\")\n",
        "        print(f\"Training Data (x_train): {x_train.shape}, Labels (y_train): {y_train.shape}\")\n",
        "        print(f\"Validation Data (x_val): {x_val.shape}, Labels (y_val): {y_val.shape}\")\n",
        "        print(f\"Testing Data (x_test): {x_test.shape}, Labels (y_test): {y_test.shape}\")\n",
        "\n",
        "        # Display 100 random rows from each dataframe\n",
        "        def display_sample(data, name):\n",
        "            print(f\"\\n{name} (100 random rows):\")\n",
        "            print(data.sample(n=100).to_string())\n",
        "\n",
        "        display_sample(df, \"Original Data\")\n",
        "        display_sample(x_train, \"Training Data (x_train)\")\n",
        "        display_sample(x_val, \"Validation Data (x_val)\")\n",
        "        display_sample(x_test, \"Testing Data (x_test)\")\n",
        "\n",
        "        print(\"\\nFeatures to Scale:\")\n",
        "        print(to_scale)  # Print the list of features subject to normalization\n",
        "\n",
        "        print(\"\\nScaler Object:\")\n",
        "        print(scaler)  # Print the scaler object\n",
        "\n",
        "    else:\n",
        "        df = result\n",
        "        print(\"Random 100 rows from the DataFrame:\")\n",
        "        print(df.sample(n=100))\n",
        "\n",
        "else:\n",
        "    print(\"No result due to error.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX1htNaK_AH5",
        "outputId": "557dd9f8-31f0-4ddc-9f95-1cfa3081bce4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes of the datasets:\n",
            "Original Data: (50892, 33)\n",
            "Training Data (x_train): (40712, 32), Labels (y_train): (40712,)\n",
            "Validation Data (x_val): (5090, 32), Labels (y_val): (5090,)\n",
            "Testing Data (x_test): (5090, 32), Labels (y_test): (5090,)\n",
            "\n",
            "Original Data (100 random rows):\n",
            "          Energy      Data   Z    N    A  Atomic_Mass_Micro  Nucleus_Radius  Neutron_Nucleus_Radius_Ratio  MT_102  MT_103  MT_104  MT_105  MT_106  MT_107  MT_108  MT_111  MT_16  MT_17  MT_179  MT_18  MT_190  MT_22  MT_28  MT_3  MT_37  MT_4  MT_51  MT_9000  MT_9001  Center_of_Mass_Flag_Center_of_Mass  Center_of_Mass_Flag_Lab  Element_Flag_I  Element_Flag_N\n",
            "68370   6.579784 -1.640165  34   46   80       7.991652e+07        5.386087                      0.148531       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "49761   7.181844 -0.716699  28   33   61       6.093105e+07        4.920621                      0.162581       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "49440   7.262451 -1.040959  28   32   60       5.993079e+07        4.893585                      0.163479       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "92950   6.840859 -0.524329  46   60  106       1.059035e+08        5.915779                      0.135232       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "95257   7.227887 -1.159267  48   64  112       1.124110e+08        6.025356                      0.132772       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "69988   7.281033 -1.166853  36   48   84       8.379800e+07        5.474399                      0.146135       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "12167   6.497483 -1.249492   8   10   18       1.799916e+07        3.275927                      0.244206       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "35127   6.185570 -3.691734  25   30   55       5.493804e+07        4.753691                      0.168290       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "68607   6.713994 -0.727230  34   46   80       7.991652e+07        5.386087                      0.148531       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "11636   6.735048 -0.486822   8   10   18       1.799916e+07        3.275927                      0.244206       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "51468   6.821291 -0.474826  28   36   64       6.392797e+07        5.000000                      0.160000       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "24090   6.518514 -2.187087  19   22   41       4.096183e+07        4.310272                      0.185603       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      1        0        0                                   1                        0               1               0\n",
            "17280   6.763937 -1.389021  12   14   26       2.598259e+07        3.703120                      0.216034       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "103326  7.255273 -0.155709  52   72  124       1.239028e+08        6.233289                      0.128343       0       0       0       0       0       0       0       0      1      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "12422   5.654850 -2.112495   8   10   18       1.799916e+07        3.275927                      0.244206       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "36552   7.126359 -0.410162  26   30   56       5.584500e+07        4.782328                      0.167283       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "40473   7.127105 -0.448428  26   30   56       5.593494e+07        4.782328                      0.167283       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "68393   6.700271 -0.903090  34   46   80       7.991652e+07        5.386087                      0.148531       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "50214   6.903090 -3.355561  28   33   61       6.093105e+07        4.920621                      0.162581       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "62214   7.060698 -0.070581  30   38   68       6.792484e+07        5.102069                      0.156799       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "8833    6.570543 -4.356547   7    8   15       1.500011e+07        3.082765                      0.259507       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "77126   7.287869 -0.156643  39   50   89       8.890584e+07        5.580931                      0.143345       0       0       0       0       0       0       0       0      1      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "82726   6.718253 -0.986703  40   54   94       9.390631e+07        5.683545                      0.140757       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "52094   6.339451 -3.356547  29   35   64       6.354600e+07        5.000000                      0.160000       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               0               1\n",
            "12444   5.772248 -0.695509   8   10   18       1.799916e+07        3.275927                      0.244206       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "101650  7.123852 -1.881735  52   76  128       1.276000e+08        6.299605                      0.126992       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "58211   6.513218 -1.562693  29   36   65       6.492779e+07        5.025907                      0.159175       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   1                        0               1               0\n",
            "57164   6.763877 -0.793849  29   34   63       6.292960e+07        4.973822                      0.160842       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "6173    5.514548 -6.045757   6    6   12       1.200000e+07        2.861786                      0.279546       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "34379   6.886491 -1.337242  24   28   52       5.194050e+07        4.665639                      0.171466       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "102905  6.995635 -0.355561  52   71  123       1.229043e+08        6.216487                      0.128690       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "79318   7.049218 -0.484391  40   51   91       9.122400e+07        5.622427                      0.142287       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "3689    5.810904 -0.366532   4    5    9       9.012183e+06        2.600105                      0.307680       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "61582   7.267172 -0.845272  30   37   67       6.692713e+07        5.076935                      0.157575       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "25744   6.543447 -0.597223  20   28   48       4.795252e+07        4.542801                      0.176103       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "118749  7.190332 -0.326979  74  110  184       1.838400e+08        7.109667                      0.112523       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "48303   6.372912 -4.498941  28   30   58       5.793534e+07        4.838596                      0.165337       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "102139  7.238046 -1.489455  52   76  128       1.276000e+08        6.299605                      0.126992       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "279     6.160775 -0.551495   1    2    3       3.016049e+06        1.802812                      0.443751       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "61020   6.919078 -0.421361  30   36   66       6.592603e+07        5.051550                      0.158367       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "3379    6.314457 -3.739929   4    5    9       9.012183e+06        2.600105                      0.307680       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   1                        0               1               0\n",
            "17913   6.909021 -1.289037  13   14   27       2.698154e+07        3.750000                      0.213333       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "52226   6.778947 -1.291180  29   35   64       6.354600e+07        5.000000                      0.160000       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "90959   6.269046 -5.559091  44   54   98       9.790529e+07        5.763045                      0.138815       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "29976   6.440909 -2.607479  22   24   46       4.595263e+07        4.478810                      0.178619       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      1        0        0                                   0                        1               1               0\n",
            "128644  7.158362 -2.677781  82  125  207       2.072000e+08        7.394352                      0.108191       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "34772   6.190332 -3.995679  24   29   53       5.294065e+07        4.695357                      0.170381       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "61041   6.804821 -1.241088  30   36   66       6.592603e+07        5.051550                      0.158367       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "49204   6.593663 -1.934981  28   32   60       5.993079e+07        4.893585                      0.163479       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      1        0        0                                   0                        1               1               0\n",
            "34216   6.213252 -4.128953  24   26   50       4.994604e+07        4.605039                      0.173723       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "99007   6.747412 -2.492144  50   69  119       1.187100e+08        6.148356                      0.130116       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "51428   6.794342 -0.521001  28   36   64       6.392797e+07        5.000000                      0.160000       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "9919    7.296665 -2.172631   8    8   16       1.599491e+07        3.149803                      0.253984       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "26653   6.692829 -0.697150  21   24   45       4.495591e+07        4.446117                      0.179932       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "3578    6.683947 -0.288193   4    5    9       9.012183e+06        2.600105                      0.307680       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "25551   6.402261 -1.056763  20   28   48       4.795252e+07        4.542801                      0.176103       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "7873    6.863323 -0.719877   7    7   14       1.400307e+07        3.012678                      0.265544       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "1119    6.356026 -0.896196   3    3    6       6.015123e+06        2.271401                      0.352206       0       0       0       0       1       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "100427  6.791761 -1.042393  50   72  122       1.219034e+08        6.199595                      0.129041       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "81929   6.954243 -0.346787  40   50   90       8.990470e+07        5.601756                      0.142812       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "32365   6.584569 -0.622657  23   28   51       5.094396e+07        4.635537                      0.172580       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "41309   7.222716 -0.879426  26   31   57       5.693539e+07        4.810626                      0.166299       0       0       0       0       0       0       0       0      1      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "14363   6.685769 -0.568878  10   12   22       2.199139e+07        3.502549                      0.228405       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "87762   6.466126 -4.659556  42   50   92       9.190681e+07        5.642947                      0.141770       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "102429  7.041393 -1.130768  52   76  128       1.276000e+08        6.299605                      0.126992       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "94841   7.225309 -1.144481  48   64  112       1.124110e+08        6.025356                      0.132772       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "88467   6.601517 -2.124389  42   53   95       9.490584e+07        5.703628                      0.140262       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "12315   6.576341 -1.044793   8   10   18       1.799916e+07        3.275927                      0.244206       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "74915   7.204120 -0.567833  38   50   88       8.762000e+07        5.559950                      0.143886       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "24300   6.269256 -3.550444  19   22   41       4.096183e+07        4.310272                      0.185603       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "8329    7.070038 -1.144481   7    7   14       1.400307e+07        3.012678                      0.265544       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "98752   6.620656 -2.458421  49   66  115       1.149039e+08        6.078680                      0.131608       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "12146   6.483872 -1.092051   8   10   18       1.799916e+07        3.275927                      0.244206       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "5445    6.784689 -1.350179   5    6   11       1.100931e+07        2.779975                      0.287772       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      1        0        0                                   0                        1               1               0\n",
            "75831   6.669596 -2.128135  38   50   88       8.790561e+07        5.559950                      0.143886       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "26318   6.513777 -1.402195  21   24   45       4.495591e+07        4.446117                      0.179932       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "87144   7.297542 -1.958607  42   54   96       9.596000e+07        5.723571                      0.139773       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        1                                   0                        1               0               1\n",
            "25175   6.421933 -1.876148  20   24   44       4.395548e+07        4.412935                      0.181285       0       1       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "32595   7.201397 -0.524329  23   28   51       5.094396e+07        4.635537                      0.172580       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "90786   7.075547 -1.546682  44   57  101       1.010700e+08        5.821262                      0.137427       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "123500  7.143015 -1.368556  79  118  197       1.969666e+08        7.273310                      0.109991       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "17718   6.812245 -1.630784  13   14   27       2.698154e+07        3.750000                      0.213333       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "83058   7.190332 -1.779630  41   52   93       9.290637e+07        5.663319                      0.141260       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "9126    6.938370 -0.946537   7    8   15       1.500011e+07        3.082765                      0.259507       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "23652   6.363988 -1.575543  19   22   41       4.096183e+07        4.310272                      0.185603       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   1                        0               1               0\n",
            "70803   6.716003 -1.090872  36   48   84       8.379800e+07        5.474399                      0.146135       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "52685   6.959041 -0.545155  29   35   64       6.354600e+07        5.000000                      0.160000       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "94862   7.033424 -1.045757  48   64  112       1.124110e+08        6.025356                      0.132772       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "124109  7.068186 -0.088842  79  118  197       1.969666e+08        7.273310                      0.109991       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               1               0\n",
            "61689   7.290035 -0.962574  30   37   67       6.692713e+07        5.076935                      0.157575       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "1443    7.113943 -0.943095   3    3    6       6.015123e+06        2.271401                      0.352206       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               1               0\n",
            "32900   6.614475 -3.596879  23   28   51       5.094396e+07        4.635537                      0.172580       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "22928   6.267875 -2.008774  17   20   37       3.696590e+07        4.165277                      0.192064       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "98727   7.040998 -3.823909  49   64  113       1.129041e+08        6.043235                      0.132379       0       0       0       1       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "23465   6.390935 -1.764472  19   22   41       4.096183e+07        4.310272                      0.185603       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   1                        0               1               0\n",
            "97237   6.857935 -0.616185  48   66  114       1.139034e+08        6.061009                      0.131991       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   1                        0               1               0\n",
            "97174   7.149835 -0.985479  48   66  114       1.139034e+08        6.061009                      0.131991       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "102777  6.869232 -1.087778  52   71  123       1.229043e+08        6.216487                      0.128690       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "36952   7.202652 -2.886057  26   30   56       5.584500e+07        4.782328                      0.167283       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "58046   6.422426 -1.892790  29   36   65       6.492779e+07        5.025907                      0.159175       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "\n",
            "Training Data (x_train) (100 random rows):\n",
            "          Energy         Z         N         A  Atomic_Mass_Micro  Nucleus_Radius  Neutron_Nucleus_Radius_Ratio  MT_102  MT_103  MT_104  MT_105  MT_106  MT_107  MT_108  MT_111  MT_16  MT_17  MT_179  MT_18  MT_190  MT_22  MT_28  MT_3  MT_37  MT_4  MT_51  MT_9000  MT_9001  Center_of_Mass_Flag_Center_of_Mass  Center_of_Mass_Flag_Lab  Element_Flag_I  Element_Flag_N\n",
            "48543   7.198657 -0.138921 -0.337570 -0.259413          -0.259738       -0.002832                     -0.259120       0       0       0       0       0       0       0       1      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "36745   7.195900 -0.233606 -0.337570 -0.296934          -0.298954       -0.044012                     -0.230246       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "17941   6.924279 -0.849053 -0.833397 -0.840992          -0.840461       -0.799536                      0.453279       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "124242  7.231470  2.275527  2.389482  2.348312           2.348623        1.779049                     -1.080614       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               1               0\n",
            "57953   6.404320 -0.091579 -0.151634 -0.128089          -0.128553        0.134255                     -0.350582       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "34093   6.786822 -0.328290 -0.461526 -0.409498          -0.409625       -0.173763                     -0.134656       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      1        0        0                                   0                        1               1               0\n",
            "10070   7.136721 -1.085764 -1.019333 -1.047359          -1.046581       -1.238799                      1.056654       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "12320   6.580697 -1.085764 -0.957354 -1.009837          -1.008979       -1.146494                      0.911513       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "5580    5.969416 -1.227790 -1.081311 -1.141162          -1.140116       -1.509463                      1.558167       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "3703    5.113943 -1.275132 -1.112300 -1.178683          -1.177584       -1.641104                      1.853652       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "23917   6.563244 -0.565000 -0.585483 -0.578343          -0.578177       -0.389494                      0.041684       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   1                        0               1               0\n",
            "32192   6.409426 -0.375632 -0.399548 -0.390737          -0.390903       -0.151443                     -0.151620       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "2746    5.894870 -1.322474 -1.143289 -1.216204          -1.215034       -1.794020                      2.252705       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "135829  7.113943  2.796290  3.133224  3.004933           3.006598        2.077270                     -1.167226       0       0       0       0       0       0       0       0      0      0       0      1       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "60166   7.245513 -0.044237 -0.182623 -0.128089          -0.120069        0.134255                     -0.350582       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "67163   6.959041  0.145131  0.127269  0.134560           0.134705        0.381364                     -0.499312       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "4472    5.079181 -1.227790 -1.112300 -1.159922          -1.158808       -1.573085                      1.696047       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "75601   6.476687  0.334500  0.220236  0.265884           0.265080        0.494038                     -0.561086       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "32629   7.100371 -0.375632 -0.399548 -0.390737          -0.390903       -0.151443                     -0.151620       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "52230   6.889077 -0.091579 -0.182623 -0.146849          -0.154476        0.115294                     -0.338340       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "7573    7.288696 -1.133106 -1.050322 -1.084880          -1.083950       -1.339156                      1.228242       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "10372   7.180126 -1.085764 -1.019333 -1.047359          -1.046581       -1.238799                      1.056654       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "93168   7.120574  0.760579  0.623096  0.678617           0.677048        0.812581                     -0.718442       0       0       0       0       0       0       0       0      1      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               0               1\n",
            "83065   7.247973  0.476526  0.344193  0.397208           0.396353        0.600753                     -0.616496       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "1939    6.357363 -1.322474 -1.143289 -1.216204          -1.215034       -1.794020                      2.252705       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "103340  7.287802  0.997289  0.963978  0.978787           0.977876        1.017894                     -0.808218       0       0       0       0       0       0       0       0      1      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "51345   6.741640 -0.138921 -0.151634 -0.146849          -0.147310        0.115294                     -0.338340       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "98992   7.078094  0.902605  0.871010  0.884984           0.880454        0.955735                     -0.781903       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "100804  6.903090  0.949947  0.932989  0.941266           0.937675        0.993235                     -0.797865       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "36344   7.107820 -0.233606 -0.337570 -0.296934          -0.298954       -0.044012                     -0.230246       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "40264   6.021189 -0.233606 -0.399548 -0.334456          -0.334701       -0.086185                     -0.199963       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "117477  7.255273  1.991474  2.079590  2.048142           2.048099        1.630851                     -1.033860       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               1               0\n",
            "12962   6.972420 -1.038422 -0.957354 -0.991077          -0.990232       -1.102893                      0.846773       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "68001   7.222716  0.145131  0.065290  0.097038           0.096431        0.347955                     -0.480308       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "86635   7.223755  0.523868  0.406172  0.453490           0.453642        0.644850                     -0.638569       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "94769   7.164353  0.807921  0.716064  0.753660           0.762279        0.865715                     -0.742478       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "138081  7.185542  2.890974  3.257181  3.117496           3.119403        2.125318                     -1.180328       0       0       0       0       0       0       0       0      0      1       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "101326  7.089905  0.997289  1.087935  1.053830           1.047239        1.066429                     -0.828272       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "28565   7.192846 -0.422974 -0.461526 -0.447019          -0.448629       -0.219313                     -0.099329       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "41865   7.000000 -0.186263 -0.275591 -0.240652          -0.241017        0.017404                     -0.273064       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "63444   6.681241 -0.044237 -0.089656 -0.071807          -0.072325        0.189995                     -0.385850       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "295     6.260846 -1.417158 -1.205268 -1.291247          -1.290077       -2.224614                      3.873340       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "3017    7.049218 -1.322474 -1.143289 -1.216204          -1.215034       -1.794020                      2.252705       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               1               0\n",
            "109559  6.869232  1.234000  1.273870  1.260196           1.259357        1.194887                     -0.879367       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "16555   6.707854 -0.896395 -0.833397 -0.859753          -0.859202       -0.833846                      0.493365       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "139065  7.079181  3.033000  3.257181  3.173778           3.175799        2.149039                     -1.186715       0       0       0       0       0       0       0       0      0      0       0      1       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "68671   7.068186  0.145131  0.158258  0.153320           0.152651        0.397857                     -0.508575       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "723     6.698970 -1.417158 -1.205268 -1.291247          -1.290077       -2.224614                      3.873340       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "101520  6.682326  0.997289  1.087935  1.053830           1.047239        1.066429                     -0.828272       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "7124    6.112960 -1.180448 -1.019333 -1.084880          -1.083946       -1.339156                      1.228242       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "23524   6.193125 -0.565000 -0.585483 -0.578343          -0.578177       -0.389494                      0.041684       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   1                        0               1               0\n",
            "57545   6.438067 -0.091579 -0.213613 -0.165610          -0.166041        0.096135                     -0.325841       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "101231  6.880814  0.949947  0.901999  0.922505           0.921612        0.980804                     -0.792603       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "10189   7.170262 -1.085764 -1.019333 -1.047359          -1.046581       -1.238799                      1.056654       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "117334  6.986772  1.991474  2.079590  2.048142           2.048099        1.630851                     -1.033860       0       0       0       0       0       0       0       0      1      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "41506   6.666237 -0.233606 -0.275591 -0.259413          -0.259776       -0.002832                     -0.259120       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "96653   7.232996  0.807921  0.716064  0.753660           0.752744        0.865715                     -0.742478       0       0       0       0       0       0       0       0      1      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "836     4.778151 -1.417158 -1.205268 -1.291247          -1.290077       -2.224614                      3.873340       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "135865  7.264818  2.796290  3.133224  3.004933           3.006598        2.077270                     -1.167226       0       0       0       0       0       0       0       0      0      0       0      1       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "126564  7.250420  2.370211  2.544428  2.479636           2.487763        1.841364                     -1.099505       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "87931   7.206016  0.523868  0.282215  0.378448           0.377600        0.585844                     -0.608927       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        1                                   0                        1               1               0\n",
            "103839  6.805501  0.997289  1.149913  1.091351           1.090506        1.090318                     -0.837988       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "73394   7.170262  0.287158  0.220236  0.247123           0.246367        0.478326                     -0.552680       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "57591   6.439285 -0.091579 -0.213613 -0.165610          -0.166041        0.096135                     -0.325841       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "41160   6.554731 -0.233606 -0.306580 -0.278174          -0.278498       -0.023302                     -0.244852       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "6212    5.704579 -1.180448 -1.081311 -1.122401          -1.121529       -1.449589                      1.436061       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "137295  6.787106  2.890974  3.102235  3.023693           3.025389        2.085335                     -1.169441       0       0       0       0       0       0       0       0      0      0       0      1       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "102787  6.924279  0.997289  0.932989  0.960026           0.959143        1.005598                     -0.803070       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "31488   6.139879 -0.422974 -0.399548 -0.409498          -0.409648       -0.173763                     -0.134656       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "5219    6.952744 -1.227790 -1.081311 -1.141162          -1.140116       -1.509463                      1.558167       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "25881   6.621176 -0.517658 -0.399548 -0.447019          -0.447025       -0.219313                     -0.099329       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "100436  6.545431  0.902605  0.963978  0.941266           0.940366        0.993235                     -0.797865       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "16463   6.740363 -0.896395 -0.864386 -0.878513          -0.877902       -0.869047                      0.535562       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               1               0\n",
            "11530   5.737113 -1.085764 -0.988343 -1.028598          -1.027741       -1.191741                      0.981236       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "30199   6.033424 -0.422974 -0.492516 -0.465780          -0.465800       -0.242564                     -0.080921       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      1        0        0                                   0                        1               1               0\n",
            "1625    6.274538 -1.322474 -1.143289 -1.216204          -1.215034       -1.794020                      2.252705       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "14786   6.750508 -0.943737 -0.895376 -0.916034          -0.915350       -0.942372                      0.627124       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "95619   6.410440  0.807921  0.530129  0.641096           0.640247        0.785520                     -0.705975       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "138014  7.146128  2.890974  3.257181  3.117496           3.119403        2.125318                     -1.180328       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "95065   6.963788  0.807921  0.716064  0.753660           0.762279        0.865715                     -0.742478       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "68626   6.726564  0.145131  0.158258  0.153320           0.152651        0.397857                     -0.508575       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "3730    5.780317 -1.275132 -1.112300 -1.178683          -1.177584       -1.641104                      1.853652       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "112701  7.096910  1.470711  1.366838  1.410281           1.409605        1.284111                     -0.913256       0       0       0       0       0       0       0       0      1      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "26824   7.245513 -0.470316 -0.523505 -0.503301          -0.503244       -0.290073                     -0.042488       0       0       0       0       0       0       0       0      1      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "63815   7.082785 -0.044237 -0.027677 -0.034286          -0.034794        0.226250                     -0.408230       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "13422   6.583199 -1.038422 -0.957354 -0.991077          -0.990232       -1.102893                      0.846773       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               1               0\n",
            "88030   6.810098  0.523868  0.344193  0.415969           0.415090        0.615556                     -0.623958       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "26954   6.400711 -0.470316 -0.523505 -0.503301          -0.503244       -0.290073                     -0.042488       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "126025  7.195900  2.322869  2.482450  2.423354           2.416602        1.814835                     -1.091516       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "103750  6.555094  0.997289  1.087935  1.053830           1.052951        1.066429                     -0.828272       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "88944   6.678063  0.523868  0.406172  0.453490           0.452604        0.644850                     -0.638569       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "13713   6.818885 -0.991079 -0.957354 -0.972316          -0.971583       -1.060796                      0.786422       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "106981  7.214844  1.091974  0.901999  0.978787           0.977934        1.017894                     -0.808218       0       0       0       0       0       0       0       0      1      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "8977    6.776193 -1.133106 -1.019333 -1.066119          -1.065244       -1.287862                      1.138633       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "10251   7.127623 -1.085764 -1.019333 -1.047359          -1.046581       -1.238799                      1.056654       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "7087    6.154214 -1.180448 -1.019333 -1.084880          -1.083946       -1.339156                      1.228242       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "135699  6.897627  2.796290  3.133224  3.004933           3.006598        2.077270                     -1.167226       0       0       0       0       0       0       0       0      0      0       0      1       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "95290   7.269513  0.807921  0.716064  0.753660           0.762279        0.865715                     -0.742478       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "127572  7.283301  2.370211  2.513439  2.460875           2.461297        1.832550                     -1.096860       0       0       0       0       0       0       0       0      0      1       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "137539  7.147058  2.890974  3.164213  3.061215           3.062991        2.101396                     -1.173833       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "\n",
            "Validation Data (x_val) (100 random rows):\n",
            "          Energy         Z         N         A  Atomic_Mass_Micro  Nucleus_Radius  Neutron_Nucleus_Radius_Ratio  MT_102  MT_103  MT_104  MT_105  MT_106  MT_107  MT_108  MT_111  MT_16  MT_17  MT_179  MT_18  MT_190  MT_22  MT_28  MT_3  MT_37  MT_4  MT_51  MT_9000  MT_9001  Center_of_Mass_Flag_Center_of_Mass  Center_of_Mass_Flag_Lab  Element_Flag_I  Element_Flag_N\n",
            "137319  7.051153  2.890974  3.102235  3.023693           3.025389        2.085335                     -1.169441       0       0       0       0       0       0       0       0      0      0       0      1       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "40583   7.269513 -0.233606 -0.337570 -0.296934          -0.297267       -0.044012                     -0.230246       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      1        0        0                                   0                        1               1               0\n",
            "82772   6.810233  0.429184  0.406172  0.415969           0.415113        0.615556                     -0.623958       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "95049   7.260071  0.807921  0.716064  0.753660           0.762279        0.865715                     -0.742478       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "115003  7.049218  1.849448  1.924644  1.898057           1.900000        1.553458                     -1.008363       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        1                                   0                        1               0               1\n",
            "100247  6.595717  0.902605  0.901999  0.903745           0.902821        0.968304                     -0.787283       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "34317   6.806180 -0.328290 -0.399548 -0.371977          -0.372207       -0.129413                     -0.168147       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "103017  6.897627  0.997289  0.963978  0.978787           0.977876        1.017894                     -0.808218       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "9389    5.769377 -1.133106 -1.019333 -1.066119          -1.065244       -1.287862                      1.138633       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "13261   6.229104 -1.038422 -0.957354 -0.991077          -0.990232       -1.102893                      0.846773       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "61487   6.954243 -0.044237 -0.120645 -0.090568          -0.091043        0.171600                     -0.374328       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "32085   6.195623 -0.375632 -0.399548 -0.390737          -0.390903       -0.151443                     -0.151620       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "13403   6.555094 -1.038422 -0.957354 -0.991077          -0.990232       -1.102893                      0.846773       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               1               0\n",
            "40614   6.903090 -0.233606 -0.337570 -0.296934          -0.297267       -0.044012                     -0.230246       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "111666  7.061829  1.376026  1.335849  1.353999           1.359459        1.251040                     -0.900842       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        1                                   0                        1               0               1\n",
            "102923  7.017033  0.997289  0.932989  0.960026           0.959143        1.005598                     -0.803070       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "36932   6.602060 -0.233606 -0.337570 -0.296934          -0.298954       -0.044012                     -0.230246       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "31486   6.120574 -0.422974 -0.399548 -0.409498          -0.409648       -0.173763                     -0.134656       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "12693   6.813754 -1.038422 -0.957354 -0.991077          -0.990232       -1.102893                      0.846773       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "97591   6.755036  0.807921  0.840021  0.828702           0.827825        0.917599                     -0.765395       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "23392   6.067443 -0.565000 -0.585483 -0.578343          -0.578177       -0.389494                      0.041684       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "23980   6.599446 -0.565000 -0.585483 -0.578343          -0.578177       -0.389494                      0.041684       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   1                        0               1               0\n",
            "101679  6.816241  0.997289  1.087935  1.053830           1.047239        1.066429                     -0.828272       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "4923    7.008600 -1.227790 -1.081311 -1.141162          -1.140116       -1.509463                      1.558167       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "36833   7.296665 -0.233606 -0.337570 -0.296934          -0.298954       -0.044012                     -0.230246       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "10225   7.110590 -1.085764 -1.019333 -1.047359          -1.046581       -1.238799                      1.056654       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "135071  7.096910  2.796290  3.133224  3.004933           3.006598        2.077270                     -1.167226       0       0       0       0       0       0       0       0      1      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "14660   6.823474 -0.943737 -0.895376 -0.916034          -0.915350       -0.942372                      0.627124       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   1                        0               1               0\n",
            "57523   6.214844 -0.091579 -0.213613 -0.165610          -0.166041        0.096135                     -0.325841       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "97157   6.845098  0.807921  0.778043  0.791181           0.790277        0.891809                     -0.754071       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "8970    6.769303 -1.133106 -1.019333 -1.066119          -1.065244       -1.287862                      1.138633       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "24296   6.229733 -0.565000 -0.585483 -0.578343          -0.578177       -0.389494                      0.041684       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "57266   6.745855 -0.091579 -0.213613 -0.165610          -0.166041        0.096135                     -0.325841       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "30205   6.107210 -0.422974 -0.492516 -0.465780          -0.465800       -0.242564                     -0.080921       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      1        0        0                                   0                        1               1               0\n",
            "100520  6.733999  0.902605  1.025956  0.978787           0.977922        1.017894                     -0.808218       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "29139   7.231979 -0.422974 -0.461526 -0.447019          -0.448629       -0.219313                     -0.099329       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "52146   6.729327 -0.091579 -0.182623 -0.146849          -0.154476        0.115294                     -0.338340       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               0               1\n",
            "51365   6.752671 -0.138921 -0.151634 -0.146849          -0.147310        0.115294                     -0.338340       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "106707  7.220108  1.091974  0.901999  0.978787           0.977934        1.017894                     -0.808218       0       0       0       0       0       0       0       0      1      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "10041   6.995635 -1.085764 -1.019333 -1.047359          -1.046581       -1.238799                      1.056654       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "26000   6.678973 -0.517658 -0.399548 -0.447019          -0.447025       -0.219313                     -0.099329       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "88555   6.755875  0.523868  0.375183  0.434729           0.433865        0.630255                     -0.631315       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "25242   6.618362 -0.517658 -0.523505 -0.522062          -0.522013       -0.314358                     -0.022407       0       1       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "135631  7.170262  2.796290  3.133224  3.004933           3.006598        2.077270                     -1.167226       0       0       0       0       0       0       0       0      0      0       0      1       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "89384   6.727053  0.523868  0.406172  0.453490           0.452604        0.644850                     -0.638569       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "7585    7.204120 -1.133106 -1.050322 -1.084880          -1.083950       -1.339156                      1.228242       0       0       0       0       0       0       0       0      0      0       0      0       0      0      1     0      0     0      0        0        0                                   0                        1               1               0\n",
            "59449   6.878866 -0.044237 -0.182623 -0.128089          -0.120069        0.134255                     -0.350582       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "98896   7.262451  0.855263  0.778043  0.809942           0.809047        0.904742                     -0.759766       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               1               0\n",
            "106417  7.267172  1.091974  0.901999  0.978787           0.977934        1.017894                     -0.808218       0       0       0       0       0       0       0       0      1      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "26861   6.024075 -0.470316 -0.523505 -0.503301          -0.503244       -0.290073                     -0.042488       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "113761  6.954243  1.660079  1.738709  1.710451           1.701997        1.453284                     -0.974189       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "2561    5.602060 -1.322474 -1.143289 -1.216204          -1.215034       -1.794020                      2.252705       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "44650   7.136721 -0.138921 -0.306580 -0.240652          -0.245523        0.017404                     -0.273064       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "51437   6.800971 -0.138921 -0.151634 -0.146849          -0.147310        0.115294                     -0.338340       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "95907   7.029384  0.807921  0.685075  0.734899           0.734009        0.852552                     -0.736578       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "51233   6.658717 -0.138921 -0.151634 -0.146849          -0.147310        0.115294                     -0.338340       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "91044   6.954243  0.618553  0.499140  0.547293           0.546426        0.716346                     -0.673384       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "94746   7.195900  0.807921  0.716064  0.753660           0.762279        0.865715                     -0.742478       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "82702   6.684396  0.429184  0.406172  0.415969           0.415113        0.615556                     -0.623958       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "40272   6.278754 -0.233606 -0.399548 -0.334456          -0.334701       -0.086185                     -0.199963       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "75587   6.446692  0.334500  0.220236  0.265884           0.265080        0.494038                     -0.561086       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "70772   6.716003  0.239816  0.220236  0.228363           0.225471        0.462490                     -0.544140       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "82471   6.725830  0.429184  0.344193  0.378448           0.377567        0.585844                     -0.608927       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "68807   6.040998  0.145131  0.220236  0.190842           0.190176        0.430436                     -0.526647       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "135012  7.235528  2.796290  3.133224  3.004933           3.006598        2.077270                     -1.167226       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "12478   6.442793 -1.085764 -0.957354 -1.009837          -1.008979       -1.146494                      0.911513       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "25344   6.280578 -0.517658 -0.399548 -0.447019          -0.447025       -0.219313                     -0.099329       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "34549   6.571709 -0.328290 -0.399548 -0.371977          -0.372207       -0.129413                     -0.168147       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "12779   6.764199 -1.038422 -0.957354 -0.991077          -0.990232       -1.102893                      0.846773       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "99978   6.924279  0.902605  0.840021  0.866223           0.865288        0.943095                     -0.776463       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "27023   6.550192 -0.470316 -0.523505 -0.503301          -0.503244       -0.290073                     -0.042488       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "75473   7.198657  0.334500  0.220236  0.265884           0.265080        0.494038                     -0.561086       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "3250    6.375664 -1.275132 -1.174279 -1.216204          -1.215016       -1.794020                      2.252705       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "61023   7.017451 -0.044237 -0.151634 -0.109328          -0.109824        0.153022                     -0.362575       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "121199  7.243038  2.038816  2.203547  2.141945           2.142024        1.678069                     -1.049045       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "94051   6.784332  0.760579  0.592107  0.659857           0.658982        0.799093                     -0.712247       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "12832   6.835215 -1.038422 -0.957354 -0.991077          -0.990232       -1.102893                      0.846773       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "40251   6.492760 -0.233606 -0.399548 -0.334456          -0.334701       -0.086185                     -0.199963       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      1        0        0                                   0                        1               1               0\n",
            "61386   6.265996 -0.044237 -0.120645 -0.090568          -0.091043        0.171600                     -0.374328       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "97433   7.131619  0.807921  0.778043  0.791181           0.790277        0.891809                     -0.754071       0       0       0       0       0       0       0       0      1      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "95903   7.012837  0.807921  0.685075  0.734899           0.734009        0.852552                     -0.736578       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "12469   6.435367 -1.085764 -0.957354 -1.009837          -1.008979       -1.146494                      0.911513       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "137915  7.021313  2.890974  3.195202  3.079975           3.081783        2.109393                     -1.176010       0       0       0       0       0       0       0       0      0      0       0      1       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "61482   6.929419 -0.044237 -0.120645 -0.090568          -0.091043        0.171600                     -0.374328       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "12306   6.571010 -1.085764 -0.957354 -1.009837          -1.008979       -1.146494                      0.911513       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "13967   6.612922 -0.991079 -0.895376 -0.934795          -0.934081       -0.980637                      0.676987       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "25576   6.423246 -0.517658 -0.399548 -0.447019          -0.447025       -0.219313                     -0.099329       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "5007    6.752509 -1.227790 -1.081311 -1.141162          -1.140116       -1.509463                      1.558167       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "26601   6.668572 -0.470316 -0.523505 -0.503301          -0.503244       -0.290073                     -0.042488       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "47117   6.919078 -0.138921 -0.306580 -0.240652          -0.245523        0.017404                     -0.273064       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        1                                   0                        1               0               1\n",
            "82749   6.762829  0.429184  0.406172  0.415969           0.415113        0.615556                     -0.623958       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "68857   6.622214  0.145131  0.220236  0.190842           0.190176        0.430436                     -0.526647       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "101669  7.127105  0.997289  1.087935  1.053830           1.047239        1.066429                     -0.828272       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "24102   6.577492 -0.565000 -0.585483 -0.578343          -0.578177       -0.389494                      0.041684       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      1        0        0                                   1                        0               1               0\n",
            "14123   6.643226 -0.991079 -0.895376 -0.934795          -0.934081       -0.980637                      0.676987       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "51399   6.776403 -0.138921 -0.151634 -0.146849          -0.147310        0.115294                     -0.338340       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "62972   7.290035 -0.044237 -0.089656 -0.071807          -0.072325        0.189995                     -0.385850       0       0       0       0       0       0       0       0      1      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "102021  7.062958  0.997289  1.087935  1.053830           1.047239        1.066429                     -0.828272       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "34198   6.357935 -0.328290 -0.461526 -0.409498          -0.409625       -0.173763                     -0.134656       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "57281   7.012837 -0.091579 -0.213613 -0.165610          -0.166041        0.096135                     -0.325841       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "\n",
            "Testing Data (x_test) (100 random rows):\n",
            "          Energy         Z         N         A  Atomic_Mass_Micro  Nucleus_Radius  Neutron_Nucleus_Radius_Ratio  MT_102  MT_103  MT_104  MT_105  MT_106  MT_107  MT_108  MT_111  MT_16  MT_17  MT_179  MT_18  MT_190  MT_22  MT_28  MT_3  MT_37  MT_4  MT_51  MT_9000  MT_9001  Center_of_Mass_Flag_Center_of_Mass  Center_of_Mass_Flag_Lab  Element_Flag_I  Element_Flag_N\n",
            "76075   6.780821  0.334500  0.282215  0.303405           0.302534        0.525102                     -0.577515       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "4897    6.705864 -1.227790 -1.081311 -1.141162          -1.140116       -1.509463                      1.558167       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "34823   6.569023 -0.328290 -0.337570 -0.334456          -0.334715       -0.086185                     -0.199963       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "76324   6.889526  0.334500  0.282215  0.303405           0.302534        0.525102                     -0.577515       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "102458  6.892095  0.997289  1.087935  1.053830           1.047239        1.066429                     -0.828272       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "41653   6.486855 -0.233606 -0.275591 -0.259413          -0.259776       -0.002832                     -0.259120       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "4665    6.487138 -1.227790 -1.081311 -1.141162          -1.140116       -1.509463                      1.558167       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "66679   6.475671  0.097789  0.034301  0.059517           0.058941        0.313962                     -0.460634       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "5105    6.857995 -1.227790 -1.081311 -1.141162          -1.140116       -1.509463                      1.558167       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "97580   6.468052  0.807921  0.840021  0.828702           0.827825        0.917599                     -0.765395       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "30445   6.619093 -0.422974 -0.492516 -0.465780          -0.465800       -0.242564                     -0.080921       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      1        0        0                                   0                        1               1               0\n",
            "36848   7.049218 -0.233606 -0.337570 -0.296934          -0.298954       -0.044012                     -0.230246       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "119071  7.285557  2.038816  2.141569  2.104424           2.102356        1.659284                     -1.043037       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "32663   7.252853 -0.375632 -0.399548 -0.390737          -0.390903       -0.151443                     -0.151620       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "52928   7.287802 -0.091579 -0.182623 -0.146849          -0.154476        0.115294                     -0.338340       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "10315   7.160288 -1.085764 -1.019333 -1.047359          -1.046581       -1.238799                      1.056654       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "44676   6.812913 -0.138921 -0.306580 -0.240652          -0.245523        0.017404                     -0.273064       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "30826   6.230449 -0.422974 -0.461526 -0.447019          -0.447111       -0.219313                     -0.099329       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      1        0        0                                   0                        1               1               0\n",
            "98845   6.442323  0.855263  0.778043  0.809942           0.809047        0.904742                     -0.759766       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "88087   6.851564  0.523868  0.344193  0.415969           0.415090        0.615556                     -0.623958       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "16309   3.217326 -0.896395 -0.864386 -0.878513          -0.877902       -0.869047                      0.535562       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      1        0        0                                   0                        1               1               0\n",
            "5503    6.896306 -1.227790 -1.081311 -1.141162          -1.140116       -1.509463                      1.558167       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      1        0        0                                   0                        1               1               0\n",
            "61730   7.016616 -0.044237 -0.120645 -0.090568          -0.091043        0.171600                     -0.374328       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "102298  7.289366  0.997289  1.087935  1.053830           1.047239        1.066429                     -0.828272       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "23981   6.600428 -0.565000 -0.585483 -0.578343          -0.578177       -0.389494                      0.041684       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   1                        0               1               0\n",
            "27603   7.187803 -0.422974 -0.461526 -0.447019          -0.448629       -0.219313                     -0.099329       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "52589   7.261263 -0.091579 -0.182623 -0.146849          -0.154476        0.115294                     -0.338340       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "69955   7.198657  0.239816  0.220236  0.228363           0.225471        0.462490                     -0.544140       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "14181   6.653772 -0.991079 -0.895376 -0.934795          -0.934081       -0.980637                      0.676987       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "138189  7.210853  2.890974  3.257181  3.117496           3.119403        2.125318                     -1.180328       0       0       0       0       0       0       0       0      0      0       0      1       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "112688  6.949390  1.470711  1.366838  1.410281           1.409605        1.284111                     -0.913256       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "137886  7.220108  2.890974  3.195202  3.079975           3.081783        2.109393                     -1.176010       0       0       0       0       0       0       0       0      0      1       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "86864   7.293141  0.523868  0.406172  0.453490           0.453642        0.644850                     -0.638569       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "25526   6.380211 -0.517658 -0.399548 -0.447019          -0.447025       -0.219313                     -0.099329       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "11904   7.198657 -1.085764 -0.957354 -1.009837          -1.008979       -1.146494                      0.911513       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "118764  7.250420  2.038816  2.141569  2.104424           2.102356        1.659284                     -1.043037       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "96269   6.989005  0.807921  0.685075  0.734899           0.734009        0.852552                     -0.736578       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "10146   6.905256 -1.085764 -1.019333 -1.047359          -1.046581       -1.238799                      1.056654       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "36876   6.995635 -0.233606 -0.337570 -0.296934          -0.298954       -0.044012                     -0.230246       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "49609   6.419956 -0.138921 -0.244602 -0.203131          -0.203535        0.057200                     -0.300029       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "11777   6.491362 -1.085764 -0.957354 -1.009837          -1.008979       -1.146494                      0.911513       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "22964   6.358125 -0.659685 -0.647462 -0.653386          -0.653145       -0.495610                      0.137582       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "82557   6.496376  0.429184  0.344193  0.378448           0.377567        0.585844                     -0.608927       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "9452    6.164947 -1.133106 -1.019333 -1.066119          -1.065244       -1.287862                      1.138633       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "10229   7.113275 -1.085764 -1.019333 -1.047359          -1.046581       -1.238799                      1.056654       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "17424   6.763503 -0.849053 -0.833397 -0.840992          -0.840461       -0.799536                      0.453279       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "62452   7.243038 -0.044237 -0.089656 -0.071807          -0.072325        0.189995                     -0.385850       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "8108    6.684235 -1.133106 -1.050322 -1.084880          -1.083950       -1.339156                      1.228242       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "57663   7.008600 -0.091579 -0.213613 -0.165610          -0.166041        0.096135                     -0.325841       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "113284  7.003461  1.565395  1.521784  1.541605           1.541044        1.359563                     -0.940952       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "23739   6.437751 -0.565000 -0.585483 -0.578343          -0.578177       -0.389494                      0.041684       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   1                        0               1               0\n",
            "27922   7.128399 -0.422974 -0.461526 -0.447019          -0.448629       -0.219313                     -0.099329       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "56941   6.489958 -0.091579 -0.213613 -0.165610          -0.166041        0.096135                     -0.325841       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "82448   6.707315  0.429184  0.344193  0.378448           0.377567        0.585844                     -0.608927       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "90518   7.176091  0.523868  0.530129  0.528532           0.527700        0.702239                     -0.666608       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        1                                   0                        1               1               0\n",
            "111228  7.111263  1.376026  1.335849  1.353999           1.359459        1.251040                     -0.900842       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "32685   7.230449 -0.375632 -0.399548 -0.390737          -0.390903       -0.151443                     -0.151620       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "111926  7.225309  1.376026  1.459806  1.429042           1.428404        1.295034                     -0.917319       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "86638   7.064458  0.523868  0.406172  0.453490           0.453642        0.644850                     -0.638569       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "63613   7.267172 -0.044237 -0.089656 -0.071807          -0.072325        0.189995                     -0.385850       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               1               0\n",
            "49424   7.071882 -0.138921 -0.275591 -0.221892          -0.222301        0.037412                     -0.286697       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "4667    6.492760 -1.227790 -1.081311 -1.141162          -1.140116       -1.509463                      1.558167       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "100507  6.565730  0.902605  1.025956  0.978787           0.977922        1.017894                     -0.808218       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "9756    7.278754 -1.085764 -1.019333 -1.047359          -1.046581       -1.238799                      1.056654       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      1        0        0                                   0                        1               1               0\n",
            "68912   7.176091  0.145131  0.220236  0.190842           0.190176        0.430436                     -0.526647       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "75757   6.430720  0.334500  0.251226  0.284645           0.283834        0.509630                     -0.569364       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "87882   7.170262  0.523868  0.282215  0.378448           0.377600        0.585844                     -0.608927       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "85475   6.985426  0.523868  0.406172  0.453490           0.453642        0.644850                     -0.638569       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "40448   6.934498 -0.233606 -0.337570 -0.296934          -0.297267       -0.044012                     -0.230246       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "132820  7.020361  2.464895  2.637396  2.573439           2.574014        1.885008                     -1.112477       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "3577    6.671173 -1.275132 -1.112300 -1.178683          -1.177584       -1.641104                      1.853652       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "4297    6.963316 -1.227790 -1.112300 -1.159922          -1.158808       -1.573085                      1.696047       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      1        0        0                                   0                        1               1               0\n",
            "64626   6.591621  0.003105 -0.089656 -0.053046          -0.053550        0.208210                     -0.397148       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "3686    5.588832 -1.275132 -1.112300 -1.178683          -1.177584       -1.641104                      1.853652       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "36923   6.785330 -0.233606 -0.337570 -0.296934          -0.298954       -0.044012                     -0.230246       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "67473   7.240549  0.145131  0.034301  0.078278           0.077657        0.331033                     -0.470557       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "4911    6.915400 -1.227790 -1.081311 -1.141162          -1.140116       -1.509463                      1.558167       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "1185    6.021189 -1.322474 -1.174279 -1.234965          -1.233811       -1.881670                      2.514540       0       0       0       0       1       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "95727   6.830909  0.807921  0.654086  0.716139           0.715226        0.839309                     -0.730606       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   1                        0               1               0\n",
            "41341   7.178977 -0.233606 -0.306580 -0.278174          -0.278498       -0.023302                     -0.244852       0       0       0       0       0       1       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "23749   6.442793 -0.565000 -0.585483 -0.578343          -0.578177       -0.389494                      0.041684       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   1                        0               1               0\n",
            "75598   6.228400  0.334500  0.220236  0.265884           0.265080        0.494038                     -0.561086       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "3389    6.316033 -1.275132 -1.112300 -1.178683          -1.177584       -1.641104                      1.853652       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   1                        0               1               0\n",
            "29949   6.214844 -0.422974 -0.523505 -0.484540          -0.484545       -0.266146                     -0.061983       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      1        0        0                                   0                        1               1               0\n",
            "51027   6.460281 -0.138921 -0.151634 -0.146849          -0.147310        0.115294                     -0.338340       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "138078  7.115943  2.890974  3.257181  3.117496           3.119403        2.125318                     -1.180328       0       0       0       0       0       0       0       0      0      1       0      0       0      0      0     0      0     0      0        0        0                                   0                        1               1               0\n",
            "51147   6.579852 -0.138921 -0.151634 -0.146849          -0.147310        0.115294                     -0.338340       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "95088   6.838849  0.807921  0.716064  0.753660           0.762279        0.865715                     -0.742478       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "103052  7.056905  0.997289  0.963978  0.978787           0.977876        1.017894                     -0.808218       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "114269  6.783904  1.754763  1.800687  1.785493           1.791280        1.493832                     -0.988186       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "57837   6.466719 -0.091579 -0.151634 -0.128089          -0.128553        0.134255                     -0.350582       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "60205   7.161368 -0.044237 -0.182623 -0.128089          -0.120069        0.134255                     -0.350582       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "35006   6.106871 -0.280948 -0.337570 -0.315695          -0.315970       -0.064971                     -0.215288       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "34756   5.954243 -0.328290 -0.368559 -0.353216          -0.353443       -0.107663                     -0.184255       1       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        0        0                                   1                        0               1               0\n",
            "88157   7.264818  0.523868  0.344193  0.415969           0.415090        0.615556                     -0.623958       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "53122   7.276462 -0.091579 -0.182623 -0.146849          -0.154476        0.115294                     -0.338340       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               0               1\n",
            "12126   6.476976 -1.085764 -0.957354 -1.009837          -1.008979       -1.146494                      0.911513       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "94417   6.757396  0.760579  0.654086  0.697378           0.696498        0.825986                     -0.724561       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "3038    6.844688 -1.322474 -1.143289 -1.216204          -1.215034       -1.794020                      2.252705       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     0      0        1        0                                   0                        1               1               0\n",
            "99799   6.782473  0.902605  0.778043  0.828702           0.827768        0.917599                     -0.765395       0       0       0       0       0       0       0       0      0      0       0      0       0      0      0     0      0     1      0        0        0                                   0                        1               1               0\n",
            "\n",
            "Features to Scale:\n",
            "['Z', 'N', 'A', 'Atomic_Mass_Micro', 'Nucleus_Radius', 'Neutron_Nucleus_Radius_Ratio']\n",
            "\n",
            "Scaler Object:\n",
            "StandardScaler()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "hdBzDeqW7EoW",
        "outputId": "a9f7e3f8-6f39-4237-ec0d-0a99744baa7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Energy      Data  Z  N  A  Atomic_Mass_Micro  Nucleus_Radius  \\\n",
              "24 -3.744727  3.152288  1  0  1          1007000.0            1.25   \n",
              "\n",
              "    Neutron_Nucleus_Radius_Ratio  MT_1  MT_101  ...  MT_33  MT_4  MT_41  \\\n",
              "24                          0.64     1       0  ...      0     0      0   \n",
              "\n",
              "    MT_51  MT_9000  MT_9001  Center_of_Mass_Flag_Center_of_Mass  \\\n",
              "24      0        0        0                                   0   \n",
              "\n",
              "    Center_of_Mass_Flag_Lab  Element_Flag_I  Element_Flag_N  \n",
              "24                        1               0               1  \n",
              "\n",
              "[1 rows x 43 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfc06bb1-2f1a-4775-a55c-563d9387a1ff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Energy</th>\n",
              "      <th>Data</th>\n",
              "      <th>Z</th>\n",
              "      <th>N</th>\n",
              "      <th>A</th>\n",
              "      <th>Atomic_Mass_Micro</th>\n",
              "      <th>Nucleus_Radius</th>\n",
              "      <th>Neutron_Nucleus_Radius_Ratio</th>\n",
              "      <th>MT_1</th>\n",
              "      <th>MT_101</th>\n",
              "      <th>...</th>\n",
              "      <th>MT_33</th>\n",
              "      <th>MT_4</th>\n",
              "      <th>MT_41</th>\n",
              "      <th>MT_51</th>\n",
              "      <th>MT_9000</th>\n",
              "      <th>MT_9001</th>\n",
              "      <th>Center_of_Mass_Flag_Center_of_Mass</th>\n",
              "      <th>Center_of_Mass_Flag_Lab</th>\n",
              "      <th>Element_Flag_I</th>\n",
              "      <th>Element_Flag_N</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>-3.744727</td>\n",
              "      <td>3.152288</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1007000.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 43 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfc06bb1-2f1a-4775-a55c-563d9387a1ff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cfc06bb1-2f1a-4775-a55c-563d9387a1ff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cfc06bb1-2f1a-4775-a55c-563d9387a1ff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "SzDZaOWuQPZp",
        "outputId": "c1c59a5a-8ebf-41cf-863e-8d59a13ef7cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Energy         Z         N         A  Atomic_Mass_Micro  \\\n",
              "3524971  2.024334  1.191378  1.243426  1.224348           1.224545   \n",
              "\n",
              "         Nucleus_Radius  Neutron_Nucleus_Radius_Ratio  MT_1  MT_101  MT_102  \\\n",
              "3524971        1.093894                     -0.799488     0       0       1   \n",
              "\n",
              "         ...  MT_33  MT_4  MT_41  MT_51  MT_9000  MT_9001  \\\n",
              "3524971  ...      0     0      0      0        0        0   \n",
              "\n",
              "         Center_of_Mass_Flag_Center_of_Mass  Center_of_Mass_Flag_Lab  \\\n",
              "3524971                                   0                        1   \n",
              "\n",
              "         Element_Flag_I  Element_Flag_N  \n",
              "3524971               1               0  \n",
              "\n",
              "[1 rows x 42 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4696de5-861f-4907-978d-bc1746242ab1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Energy</th>\n",
              "      <th>Z</th>\n",
              "      <th>N</th>\n",
              "      <th>A</th>\n",
              "      <th>Atomic_Mass_Micro</th>\n",
              "      <th>Nucleus_Radius</th>\n",
              "      <th>Neutron_Nucleus_Radius_Ratio</th>\n",
              "      <th>MT_1</th>\n",
              "      <th>MT_101</th>\n",
              "      <th>MT_102</th>\n",
              "      <th>...</th>\n",
              "      <th>MT_33</th>\n",
              "      <th>MT_4</th>\n",
              "      <th>MT_41</th>\n",
              "      <th>MT_51</th>\n",
              "      <th>MT_9000</th>\n",
              "      <th>MT_9001</th>\n",
              "      <th>Center_of_Mass_Flag_Center_of_Mass</th>\n",
              "      <th>Center_of_Mass_Flag_Lab</th>\n",
              "      <th>Element_Flag_I</th>\n",
              "      <th>Element_Flag_N</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3524971</th>\n",
              "      <td>2.024334</td>\n",
              "      <td>1.191378</td>\n",
              "      <td>1.243426</td>\n",
              "      <td>1.224348</td>\n",
              "      <td>1.224545</td>\n",
              "      <td>1.093894</td>\n",
              "      <td>-0.799488</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 42 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4696de5-861f-4907-978d-bc1746242ab1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b4696de5-861f-4907-978d-bc1746242ab1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b4696de5-861f-4907-978d-bc1746242ab1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x_train"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Relabel columns 'Z' to 'Zz' and 'N' to 'Nn' in the DataFrame 'df'\n",
        "df.rename(columns={'Z': 'Zz', 'N': 'Nn'}, inplace=True)\n"
      ],
      "metadata": {
        "id": "e5SDs3PC41Ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DT Machine Learning V6"
      ],
      "metadata": {
        "id": "xXNVidVPsiT0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zIVoUOX03vqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definitions"
      ],
      "metadata": {
        "id": "SjpHb4Cnfdrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate means and standard deviations using NumPy\n",
        "mean_Zz = np.mean(df['Zz'])\n",
        "std_Zz = np.std(df['Zz'])\n",
        "mean_Nn = np.mean(df['Nn'])\n",
        "std_Nn = np.std(df['Nn'])\n",
        "mean_Z = np.mean(x_train['Z'])\n",
        "std_Z = np.std(x_train['Z'])\n",
        "mean_N = np.mean(x_train['N'])\n",
        "std_N = np.std(x_train['N'])\n",
        "\n",
        "# Function to map a range from Zz/Nn to Z/N\n",
        "def map_range(zz_range, nn_range):\n",
        "    zz_lower, zz_upper = zz_range\n",
        "    nn_lower, nn_upper = nn_range\n",
        "\n",
        "    # Standardize the range\n",
        "    zz_lower_standardized = (zz_lower - mean_Zz) / std_Zz\n",
        "    zz_upper_standardized = (zz_upper - mean_Zz) / std_Zz\n",
        "    nn_lower_standardized = (nn_lower - mean_Nn) / std_Nn\n",
        "    nn_upper_standardized = (nn_upper - mean_Nn) / std_Nn\n",
        "\n",
        "    # Map the standardized range to Z and N distributions\n",
        "    z_lower_mapped = zz_lower_standardized * std_Z + mean_Z\n",
        "    z_upper_mapped = zz_upper_standardized * std_Z + mean_Z\n",
        "    n_lower_mapped = nn_lower_standardized * std_N + mean_N\n",
        "    n_upper_mapped = nn_upper_standardized * std_N + mean_N\n",
        "\n",
        "    return (z_lower_mapped, z_upper_mapped), (n_lower_mapped, n_upper_mapped)\n",
        "    # Save headers\n",
        "def save_column_headers(df, directory):\n",
        "    headers = df.columns.tolist()\n",
        "    headers.insert(0, 'data_columns')  # Add 'data_columns' as the first element\n",
        "    headers_df = pd.DataFrame(headers, columns=['Header'])\n",
        "    headers_filepath = os.path.join(directory, 'column_headers.csv')\n",
        "    headers_df.to_csv(headers_filepath, index=False, header=False)\n",
        "    print(f\"Column headers saved successfully to: {headers_filepath}\")\n",
        "\n",
        "def filter_data_based_on_ranges(x_train, x_test, x_val, Z_range, N_range):\n",
        "    def filter_df(df, Z_range, N_range):\n",
        "        return df[(df['Z'].between(Z_range[0], Z_range[1])) &\n",
        "                  (df['N'].between(N_range[0], N_range[1]))]\n",
        "\n",
        "    # Filter datasets\n",
        "    x_train_filtered = filter_df(x_train, Z_range, N_range)\n",
        "    x_test_filtered = filter_df(x_test, Z_range, N_range)\n",
        "    x_val_filtered = filter_df(x_val, Z_range, N_range)\n",
        "\n",
        "\n",
        "\n",
        "    return x_train_filtered, x_test_filtered, x_val_filtered\n",
        "\n",
        "def apply_fraction_scaling(x_train, x_test, x_val, fraction):\n",
        "    def scale_df(df, fraction):\n",
        "        if fraction < 1:\n",
        "            return df.sample(frac=fraction, random_state=42).reset_index(drop=True)\n",
        "        return df\n",
        "\n",
        "    # Apply scaling to each dataset\n",
        "    x_train_scaled = scale_df(x_train, fraction)\n",
        "    x_test_scaled = scale_df(x_test, fraction)\n",
        "    x_val_scaled = scale_df(x_val, fraction)\n",
        "\n",
        "\n",
        "\n",
        "    return x_train_scaled, x_test_scaled, x_val_scaled\n",
        "\n",
        "def limit_rows_per_combination(x_train, y_train, x_test, y_test, x_val, y_val, max_rows_per_combination_train):\n",
        "    total_size = len(x_train) + len(x_val) + len(x_test)\n",
        "    train_ratio = len(x_train) / total_size\n",
        "    val_ratio = len(x_val) / total_size\n",
        "    test_ratio = len(x_test) / total_size\n",
        "\n",
        "    max_rows_per_combination_val = int(max_rows_per_combination_train * val_ratio / train_ratio)\n",
        "    max_rows_per_combination_test = int(max_rows_per_combination_train * test_ratio / train_ratio)\n",
        "\n",
        "    def limit_rows(df_x, df_y, max_rows_per_combination):\n",
        "        combined = pd.concat([df_x, df_y], axis=1)\n",
        "        grouped = combined.groupby(['Z', 'N'])\n",
        "        final_combined = grouped.apply(lambda group: group.sample(n=min(len(group), max_rows_per_combination), random_state=42))\n",
        "        final_combined.reset_index(drop=True, inplace=True)\n",
        "        return final_combined.iloc[:, :-1], final_combined.iloc[:, -1]\n",
        "\n",
        "    # Limit rows per combination for each dataset\n",
        "    x_train_final, y_train_final = limit_rows(x_train, y_train, max_rows_per_combination_train)\n",
        "    x_val_final, y_val_final = limit_rows(x_val, y_val, max_rows_per_combination_val)\n",
        "    x_test_final, y_test_final = limit_rows(x_test, y_test, max_rows_per_combination_test)\n",
        "\n",
        "\n",
        "    return x_train_final, y_train_final, x_val_final, y_val_final, x_test_final, y_test_final\n",
        "\n",
        "x_train_final, y_train_final, x_val_final, y_val_final, x_test_final, y_test_final = limit_rows_per_combination(\n",
        "    x_train_scaled, y_train, x_test_scaled, y_test, x_val_scaled, y_val, max_rows_per_combination_train\n",
        ")\n"
      ],
      "metadata": {
        "id": "p1oGgP-lfoZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree"
      ],
      "metadata": {
        "id": "R5Pq5RYzfpfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "note = \"All rows\"\n",
        "gc.collect()\n",
        "\n",
        "# Define the base saving directory\n",
        "base_saving_directory = \"/content/drive/My Drive/ML_Nuclear_Data/ML_Saving_Directory\"\n",
        "\n",
        "# Generate a folder name based on note, basic, and mode\n",
        "folder_name = f\"{note}_basic={basic}_{mode}\"\n",
        "model_saving_directory = os.path.join(base_saving_directory, folder_name)\n",
        "\n",
        "# Ensure the directory exists\n",
        "if not os.path.exists(model_saving_directory):\n",
        "    os.makedirs(model_saving_directory)\n",
        "    print(f\"Folder '{folder_name}' has been generated at: {model_saving_directory}\")\n",
        "else:\n",
        "    print(f\"Folder '{folder_name}' already exists at: {model_saving_directory}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea4rNEJSslvb",
        "outputId": "93e3534c-f8f4-472e-a00a-3893f4a2216f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder 'All rows_basic=1_neutrons' already exists at: /content/drive/My Drive/ML_Nuclear_Data/ML_Saving_Directory/All rows_basic=1_neutrons\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the specific values for each parameter\n",
        "max_depth_values = [70, 76, 82, 88]\n",
        "min_samples_split_values = [6, 7, 8]\n",
        "min_samples_leaf_values = [6, 7, 8]\n",
        "\n",
        "# Generate all combinations of the parameters\n",
        "param_combinations = [\n",
        "    {\"max_depth\": md, \"min_samples_split\": mss, \"min_samples_leaf\": msl}\n",
        "    for md in max_depth_values\n",
        "    for mss in min_samples_split_values\n",
        "    for msl in min_samples_leaf_values\n",
        "]\n",
        "\n",
        "from sklearn import tree\n",
        "from joblib import dump\n",
        "\n",
        "# Ensure correct shapes of data are used\n",
        "print(f\"Training Data (x_train): {x_train.shape}, Labels (y_train): {y_train.shape}\")\n",
        "print(f\"Validation Data (x_val): {x_val.shape}, Labels (y_val): {y_val.shape}\")\n",
        "print(f\"Testing Data (x_test): {x_test.shape}, Labels (y_test): {y_test.shape}\")\n",
        "print(x_train[['Z', 'N']].describe())\n",
        "print(x_val[['Z', 'N']].describe())\n",
        "print(x_test[['Z', 'N']].describe())\n"
      ],
      "metadata": {
        "id": "BRx7dbpDtjei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "885f3d6f-8e7f-4cfd-9195-2833a5be9cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data (x_train): (3458096, 42), Labels (y_train): (3458096,)\n",
            "Validation Data (x_val): (432263, 42), Labels (y_val): (432263,)\n",
            "Testing Data (x_test): (432263, 42), Labels (y_test): (432263,)\n",
            "                  Z             N\n",
            "count  3.458096e+06  3.458096e+06\n",
            "mean  -3.840684e-06 -9.660466e-06\n",
            "std    9.998899e-01  9.998914e-01\n",
            "min   -1.632370e+00 -1.457749e+00\n",
            "25%   -8.566153e-01 -8.950040e-01\n",
            "50%   -1.118904e-01 -1.634358e-01\n",
            "75%    1.191378e+00  1.205910e+00\n",
            "max    1.408590e+00  1.468524e+00\n",
            "                   Z              N\n",
            "count  432263.000000  432263.000000\n",
            "mean        0.000031       0.000077\n",
            "std         1.000883       1.000871\n",
            "min        -1.632370      -1.457749\n",
            "25%        -0.856615      -0.895004\n",
            "50%        -0.111890      -0.163436\n",
            "75%         1.191378       1.205910\n",
            "max         1.408590       1.449766\n",
            "                   Z              N\n",
            "count  432263.000000  432263.000000\n",
            "mean       -0.000699      -0.000770\n",
            "std         0.999586       0.999661\n",
            "min        -1.632370      -1.457749\n",
            "25%        -0.856615      -0.895004\n",
            "50%        -0.111890      -0.163436\n",
            "75%         1.191378       1.205910\n",
            "max         1.408590       1.468524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zz_range = (0, 50) #min 1, max 99\n",
        "nn_range = (0, 82) #min 0, max 156\n",
        "\n",
        "mapped_z_range, mapped_n_range = map_range(zz_range, nn_range)\n",
        "\n",
        "print(f\"Mapped Z range: {mapped_z_range}\")\n",
        "print(f\"Mapped N range: {mapped_n_range}\")\n",
        "\n",
        "# Define the dynamic ranges for Z and N\n",
        "Z_range = mapped_z_range  # Dynamic range for Z\n",
        "N_range = mapped_z_range  # Dynamic range for N\n",
        "\n",
        "# Redefine scale factors\n",
        "fraction = 0.5\n",
        "train_fraction = fraction\n",
        "val_fraction = fraction\n",
        "test_fraction = fraction\n",
        "apply_scaling = False  # Set to False to ignore scaling\n",
        "\n",
        "max_rows_per_combination_train = 1000\n",
        "\n",
        "# Save headers for x_train\n",
        "save_column_headers(x_train, model_saving_directory)\n",
        "\n",
        "# Define scaler saving path outside the loop\n",
        "scaler_saving_path = os.path.join(model_saving_directory, 'scaler.pkl')\n",
        "dump(scaler, scaler_saving_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioloiRLUahoj",
        "outputId": "e8d35bb7-5029-45db-f95e-67b803a3d61b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped Z range: (-1.6632201668325801, -0.11181671488986555)\n",
            "Mapped N range: (-1.4575724825940406, 0.08048164410496696)\n",
            "Column headers saved successfully to: /content/drive/My Drive/ML_Nuclear_Data/ML_Saving_Directory/All rows_basic=1_neutrons/column_headers.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/ML_Nuclear_Data/ML_Saving_Directory/All rows_basic=1_neutrons/scaler.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Z and N\n",
        "x_train_filtered, x_test_filtered, x_val_filtered = filter_data_based_on_ranges(\n",
        "    x_train, x_test, x_val, Z_range, N_range\n",
        ")\n",
        "\n",
        "# Displaying the shapes of the filtered data\n",
        "print(f\"ZN Filtered Training Data: {x_train_filtered.shape}\")\n",
        "print(f\"ZN Filtered Testing Data: {x_test_filtered.shape}\")\n",
        "print(f\"ZN Filtered Validation Data: {x_val_filtered.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmkx0V47bXsp",
        "outputId": "1de08f07-ee26-42ae-ea02-3d51184b5d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZN Filtered Training Data: (1750647, 42)\n",
            "ZN Filtered Testing Data: (219151, 42)\n",
            "ZN Filtered Validation Data: (219029, 42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fraction scaling\n",
        "\n",
        "x_train_scaled, x_test_scaled, x_val_scaled = apply_fraction_scaling(x_train_filtered, x_test_filtered, x_val_filtered, fraction)\n",
        "\n",
        "# Displaying the shapes of the scaled data\n",
        "print(f\"ZNFraction Scaled Training Data: {x_train_scaled.shape}\")\n",
        "print(f\"ZNFraction Scaled Testing Data: {x_test_scaled.shape}\")\n",
        "print(f\"ZNFraction Scaled Validation Data: {x_val_scaled.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePnsR_7Dd6dq",
        "outputId": "b381662a-c166-40a6-adf1-d0b197775915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZNFraction Scaled Training Data: (875324, 42)\n",
            "ZNFraction Scaled Testing Data: (109576, 42)\n",
            "ZNFraction Scaled Validation Data: (109514, 42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# max row\n",
        "x_train_final, y_train_final, x_val_final, y_val_final, x_test_final, y_test_final = limit_rows_per_combination(\n",
        "    x_train_scaled, y_train, x_test_scaled, y_test, x_val_scaled, y_val, max_rows_per_combination_train\n",
        ")\n",
        "\n",
        "# Displaying the shapes of the final data\n",
        "print(f\"Final Training Data: {x_train_final.shape}\")\n",
        "print(f\"Final Validation Data: {x_val_final.shape}\")\n",
        "print(f\"Final Testing Data: {x_test_final.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Alldi1hXeUIa",
        "outputId": "f768e74a-fd65-404f-a528-e0b45637b3d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Training Data: (101274, 42)\n",
            "Final Validation Data: (12631, 42)\n",
            "Final Testing Data: (12692, 42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "awjwU6IOhUrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a list to compile all results\n",
        "all_results = []\n",
        "\n",
        "# Iterate over parameter combinations\n",
        "for i, params in enumerate(param_combinations):\n",
        "    print(f\"Training model {i + 1} with parameters: {params}\")\n",
        "\n",
        "    # Initializing the model instance with current parameters\n",
        "    dt_model = tree.DecisionTreeRegressor(**params)\n",
        "\n",
        "    # Training the model\n",
        "    print(f\"Training with x_train_final shape: {x_train_final.shape}, y_train_final shape: {y_train_final.shape}\")\n",
        "    dt_model.fit(x_train_final, y_train_final)\n",
        "\n",
        "    # Making model predictions to calculate metrics\n",
        "    y_hat_train = dt_model.predict(x_train_final)\n",
        "    y_hat_val = dt_model.predict(x_val_final)\n",
        "    y_hat_test = dt_model.predict(x_test_final)\n",
        "\n",
        "    # Output prediction stats\n",
        "    print(f\"Predictions on training data: {y_hat_train[:5]}\")\n",
        "    print(f\"Predictions on validation data: {y_hat_val[:5]}\")\n",
        "    print(f\"Predictions on testing data: {y_hat_test[:5]}\")\n",
        "\n",
        "    # Getting performance metrics using model_utils from NucML (ensure model_utils is defined/imported correctly)\n",
        "    train_error_metrics = model_utils.regression_error_metrics(y_hat_train, y_train_final)\n",
        "    val_error_metrics = model_utils.regression_error_metrics(y_hat_val, y_val_final)\n",
        "    test_error_metrics = model_utils.regression_error_metrics(y_hat_test, y_test_final)\n",
        "\n",
        "    # Specify the path and name for the model\n",
        "    model_name = f\"dt_model_{i+1}_mss{params['min_samples_split']}_msl{params['min_samples_leaf']}_maxdepth{params['max_depth']}.joblib\"\n",
        "    model_saving_path = os.path.join(model_saving_directory, model_name)\n",
        "\n",
        "    # Compile results into a dictionary\n",
        "    result = {\n",
        "        \"id\": i + 1,\n",
        "        \"max_depth\": params[\"max_depth\"],\n",
        "        \"mss\": params[\"min_samples_split\"],\n",
        "        \"msl\": params[\"min_samples_leaf\"],\n",
        "        \"normalizer\": \"standard_scaler\",\n",
        "        \"train_mae\": train_error_metrics['mae'],\n",
        "        \"train_mse\": train_error_metrics['mse'],\n",
        "        \"train_evs\": train_error_metrics['evs'],\n",
        "        \"train_r2\": train_error_metrics['r2'],\n",
        "        \"val_mae\": val_error_metrics['mae'],\n",
        "        \"val_mse\": val_error_metrics['mse'],\n",
        "        \"val_evs\": val_error_metrics['evs'],\n",
        "        \"val_r2\": val_error_metrics['r2'],\n",
        "        \"test_mae\": test_error_metrics['mae'],\n",
        "        \"test_mse\": test_error_metrics['mse'],\n",
        "        \"test_evs\": test_error_metrics['evs'],\n",
        "        \"test_r2\": test_error_metrics['r2'],\n",
        "        \"model_path\": os.path.abspath(model_saving_path),\n",
        "        \"scaler_path\": os.path.abspath(scaler_saving_path)\n",
        "    }\n",
        "\n",
        "    # Ensure the directory exists\n",
        "    os.makedirs(os.path.dirname(model_saving_path), exist_ok=True)\n",
        "\n",
        "    # Save the model\n",
        "    dump(dt_model, model_saving_path)\n",
        "\n",
        "    # Append the results to the list\n",
        "    all_results.append(result)\n",
        "\n",
        "    print(f\"Results saved for model {i + 1}\")\n",
        "\n",
        "# Convert the list of results to a DataFrame and reorder columns\n",
        "required_columns = [\"id\", \"max_depth\", \"mss\", \"msl\", \"normalizer\", \"train_mae\", \"train_mse\", \"train_evs\", \"train_r2\",\n",
        "                    \"val_mae\", \"val_mse\", \"val_evs\", \"val_r2\", \"test_mae\", \"test_mse\", \"test_evs\", \"test_r2\",\n",
        "                    \"model_path\", \"scaler_path\"]\n",
        "results_df = pd.DataFrame(all_results)\n",
        "results_df = results_df[required_columns]\n",
        "\n",
        "# Save as a CSV file with the specified filename\n",
        "all_results_filepath = os.path.join(model_saving_directory, all_results_filename)\n",
        "results_df.to_csv(all_results_filepath, index=False)\n",
        "\n",
        "print(f\"All results compiled and saved to {all_results_filepath}\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "display(results_df)"
      ],
      "metadata": {
        "id": "FSoOlhqPYV5P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "313400c1-0c10-4c20-bf0a-eb643615a285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model 1 with parameters: {'max_depth': 70, 'min_samples_split': 6, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (101274, 42), y_train_final shape: (101274,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input y contains NaN.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-1f7d9ea3d490>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training with x_train_final shape: {x_train_final.shape}, y_train_final shape: {y_train_final.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Making model predictions to calculate metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcheck_X_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dDQLzjS8S3oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DT Machine Learning V7"
      ],
      "metadata": {
        "id": "ze6GE4XsiGqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definitions"
      ],
      "metadata": {
        "id": "_vR2SAReiGqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Relabel columns 'Z' to 'Zz' and 'N' to 'Nn' in the DataFrame 'df'\n",
        "df.rename(columns={'Z': 'Zz', 'N': 'Nn'}, inplace=True)\n"
      ],
      "metadata": {
        "id": "IjNIURIIwkM2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate means and standard deviations using NumPy\n",
        "mean_Zz = np.mean(df['Zz'])\n",
        "std_Zz = np.std(df['Zz'])\n",
        "mean_Nn = np.mean(df['Nn'])\n",
        "std_Nn = np.std(df['Nn'])\n",
        "mean_Z = np.mean(x_train['Z'])\n",
        "std_Z = np.std(x_train['Z'])\n",
        "mean_N = np.mean(x_train['N'])\n",
        "std_N = np.std(x_train['N'])\n",
        "\n",
        "# Function to map a range from Zz/Nn to Z/N\n",
        "def map_range(zz_range, nn_range):\n",
        "    zz_lower, zz_upper = zz_range\n",
        "    nn_lower, nn_upper = nn_range\n",
        "\n",
        "    # Standardize the range\n",
        "    zz_lower_standardized = (zz_lower - mean_Zz) / std_Zz\n",
        "    zz_upper_standardized = (zz_upper - mean_Zz) / std_Zz\n",
        "    nn_lower_standardized = (nn_lower - mean_Nn) / std_Nn\n",
        "    nn_upper_standardized = (nn_upper - mean_Nn) / std_Nn\n",
        "\n",
        "    # Map the standardized range to Z and N distributions\n",
        "    z_lower_mapped = zz_lower_standardized * std_Z + mean_Z\n",
        "    z_upper_mapped = zz_upper_standardized * std_Z + mean_Z\n",
        "    n_lower_mapped = nn_lower_standardized * std_N + mean_N\n",
        "    n_upper_mapped = nn_upper_standardized * std_N + mean_N\n",
        "\n",
        "    return (z_lower_mapped, z_upper_mapped), (n_lower_mapped, n_upper_mapped)\n",
        "\n",
        "# Save headers\n",
        "def save_column_headers(df, directory):\n",
        "    headers = df.columns.tolist()\n",
        "    headers.insert(0, 'data_columns')  # Add 'data_columns' as the first element\n",
        "    headers_df = pd.DataFrame(headers, columns=['Header'])\n",
        "    headers_filepath = os.path.join(directory, 'column_headers.csv')\n",
        "    headers_df.to_csv(headers_filepath, index=False, header=False)\n",
        "    print(f\"Column headers saved successfully to: {headers_filepath}\")\n",
        "\n",
        "def filter_data_based_on_ranges(x_train, y_train, x_test, y_test, x_val, y_val, Z_range, N_range):\n",
        "    def filter_df(df, Z_range, N_range):\n",
        "        return df[(df['Z'].between(Z_range[0], Z_range[1])) &\n",
        "                  (df['N'].between(N_range[0], N_range[1]))]\n",
        "\n",
        "    # Filter datasets\n",
        "    x_train_filtered = filter_df(x_train, Z_range, N_range)\n",
        "    x_test_filtered = filter_df(x_test, Z_range, N_range)\n",
        "    x_val_filtered = filter_df(x_val, Z_range, N_range)\n",
        "\n",
        "    y_train_filtered = y_train.loc[x_train_filtered.index]\n",
        "    y_test_filtered = y_test.loc[x_test_filtered.index]\n",
        "    y_val_filtered = y_val.loc[x_val_filtered.index]\n",
        "\n",
        "    return x_train_filtered, y_train_filtered, x_test_filtered, y_test_filtered, x_val_filtered, y_val_filtered\n",
        "\n",
        "def apply_fraction_scaling(x_train, y_train, x_test, y_test, x_val, y_val, fraction):\n",
        "    def scale_df(df, fraction):\n",
        "        if fraction < 1:\n",
        "            return df.sample(frac=fraction, random_state=42).reset_index(drop=True)\n",
        "        return df.reset_index(drop=True)  # Ensure the index is reset even if fraction is 1\n",
        "\n",
        "    # Reset indices before scaling to ensure alignment\n",
        "    x_train = x_train.reset_index(drop=True)\n",
        "    y_train = y_train.reset_index(drop=True)\n",
        "    x_test = x_test.reset_index(drop=True)\n",
        "    y_test = y_test.reset_index(drop=True)\n",
        "    x_val = x_val.reset_index(drop=True)\n",
        "    y_val = y_val.reset_index(drop=True)\n",
        "\n",
        "    # Apply scaling to each dataset\n",
        "    x_train_scaled = scale_df(x_train, fraction)\n",
        "    y_train_scaled = y_train.loc[x_train_scaled.index]\n",
        "    x_test_scaled = scale_df(x_test, fraction)\n",
        "    y_test_scaled = y_test.loc[x_test_scaled.index]\n",
        "    x_val_scaled = scale_df(x_val, fraction)\n",
        "    y_val_scaled = y_val.loc[x_val_scaled.index]\n",
        "\n",
        "    return x_train_scaled, y_train_scaled, x_test_scaled, y_test_scaled, x_val_scaled, y_val_scaled\n",
        "\n",
        "def limit_rows_per_combination(x_train, y_train, x_test, y_test, x_val, y_val, max_rows_per_combination_train):\n",
        "    total_size = len(x_train) + len(x_val) + len(x_test)\n",
        "    train_ratio = len(x_train) / total_size\n",
        "    val_ratio = len(x_val) / total_size\n",
        "    test_ratio = len(x_test) / total_size\n",
        "\n",
        "    max_rows_per_combination_val = int(max_rows_per_combination_train * val_ratio / train_ratio)\n",
        "    max_rows_per_combination_test = int(max_rows_per_combination_train * test_ratio / train_ratio)\n",
        "\n",
        "    def limit_rows(df_x, df_y, max_rows_per_combination):\n",
        "        combined = pd.concat([df_x, df_y], axis=1)\n",
        "        grouped = combined.groupby(['Z', 'N'])\n",
        "        final_combined = grouped.apply(lambda group: group.sample(n=min(len(group), max_rows_per_combination), random_state=42))\n",
        "        final_combined.reset_index(drop=True, inplace=True)\n",
        "        return final_combined.iloc[:, :-1], final_combined.iloc[:, -1]\n",
        "\n",
        "    # Limit rows per combination for each dataset\n",
        "    x_train_final, y_train_final = limit_rows(x_train, y_train, max_rows_per_combination_train)\n",
        "    x_val_final, y_val_final = limit_rows(x_val, y_val, max_rows_per_combination_val)\n",
        "    x_test_final, y_test_final = limit_rows(x_test, y_test, max_rows_per_combination_test)\n",
        "\n",
        "    return x_train_final, y_train_final, x_val_final, y_val_final, x_test_final, y_test_final\n",
        "\n",
        "\n",
        "from sklearn import tree\n",
        "from joblib import dump\n"
      ],
      "metadata": {
        "id": "P2COXHRNiGqX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree"
      ],
      "metadata": {
        "id": "uas0i1gniGqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "note = \"All Rows\"\n",
        "gc.collect()\n",
        "\n",
        "# Define the base saving directory\n",
        "base_saving_directory = \"/content/drive/My Drive/ML_Nuclear_Data/ML_Saving_Directory\"\n",
        "\n",
        "# Generate a folder name based on note, basic, and mode\n",
        "folder_name = f\"{note}_basic={basic}_{mode}\"\n",
        "model_saving_directory = os.path.join(base_saving_directory, folder_name)\n",
        "\n",
        "# Ensure the directory exists\n",
        "if not os.path.exists(model_saving_directory):\n",
        "    os.makedirs(model_saving_directory)\n",
        "    print(f\"Folder '{folder_name}' has been generated at: {model_saving_directory}\")\n",
        "else:\n",
        "    print(f\"Folder '{folder_name}' already exists at: {model_saving_directory}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d6543c0-349e-4189-d397-4004014d88a0",
        "id": "zE4HD_gwiGqX"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder 'All Rows_basic=1_protons' has been generated at: /content/drive/My Drive/ML_Nuclear_Data/ML_Saving_Directory/All Rows_basic=1_protons\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standards\n",
        "#max_depth_values = [70, 76, 82, 88]\n",
        "#min_samples_split_values = [6, 7, 8]\n",
        "#min_samples_leaf_values = [6, 7, 8]"
      ],
      "metadata": {
        "id": "WqZY5GlxgnBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the specific values for each parameter\n",
        "max_depth_values = [10, 30, 50, 70, 76, 82, 88, 150, 300]\n",
        "min_samples_split_values = [2, 3, 4, 5, 6, 7, 8]\n",
        "min_samples_leaf_values = [2, 3, 4, 5, 6, 7, 8]\n",
        "\n",
        "# Generate all combinations of the parameters\n",
        "param_combinations = [\n",
        "    {\"max_depth\": md, \"min_samples_split\": mss, \"min_samples_leaf\": msl}\n",
        "    for md in max_depth_values\n",
        "    for mss in min_samples_split_values\n",
        "    for msl in min_samples_leaf_values\n",
        "]\n",
        "\n",
        "# Generate a filename that includes the specific values\n",
        "all_results_filename = \"all_results_maxdepth({})_mss({})_msl({}).csv\".format(\n",
        "    '-'.join(map(str, max_depth_values)),\n",
        "    '-'.join(map(str, min_samples_split_values)),\n",
        "    '-'.join(map(str, min_samples_leaf_values))\n",
        ")\n",
        "\n",
        "(f\"All Results Filename: {all_results_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "64010780-e3c6-485c-aebe-fae9d329dc0a",
        "id": "aqovzX6GiGqX"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'All Results Filename: all_results_maxdepth(10-30-50-70-76-82-88-150-300)_mss(2-3-4-5-6-7-8)_msl(2-3-4-5-6-7-8).csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zz_range = (1, 99) #min 1, max 99\n",
        "nn_range = (0, 156) #min 0, max 156\n",
        "\n",
        "mapped_z_range, mapped_n_range = map_range(zz_range, nn_range)\n",
        "\n",
        "print(f\"Mapped Z range: {mapped_z_range}\")\n",
        "print(f\"Mapped N range: {mapped_n_range}\")\n",
        "\n",
        "# Define the dynamic ranges for Z and N\n",
        "Z_range = mapped_z_range  # Dynamic range for Z\n",
        "N_range = mapped_z_range  # Dynamic range for N\n",
        "\n",
        "# Redefine scale factors\n",
        "fraction = 1\n",
        "train_fraction = fraction\n",
        "val_fraction = fraction\n",
        "test_fraction = fraction\n",
        "apply_scaling = True  # Set to False to ignore scaling\n",
        "\n",
        "max_rows_per_combination_train = 2000000000\n",
        "\n",
        "# Save headers for x_train\n",
        "save_column_headers(x_train, model_saving_directory)\n",
        "\n",
        "# Define scaler saving path outside the loop\n",
        "scaler_saving_path = os.path.join(model_saving_directory, 'scaler.pkl')\n",
        "dump(scaler, scaler_saving_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c04ca7db-00d7-4a01-c3b6-05c81ff10546",
        "id": "cDFQn9w5iGqX"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped Z range: (-1.419450584046297, 3.2203280967167074)\n",
            "Mapped N range: (-1.268778330382778, 3.5640791927244098)\n",
            "Column headers saved successfully to: /content/drive/My Drive/ML_Nuclear_Data/ML_Saving_Directory/All Rows_basic=1_protons/column_headers.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/ML_Nuclear_Data/ML_Saving_Directory/All Rows_basic=1_protons/scaler.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Original Data\n",
        "print(f\"Training Data (x_train): {x_train.shape}, Labels (y_train): {y_train.shape}\")\n",
        "print(f\"Validation Data (x_val): {x_val.shape}, Labels (y_val): {y_val.shape}\")\n",
        "print(f\"Testing Data (x_test): {x_test.shape}, Labels (y_test): {y_test.shape}\")\n",
        "\n",
        "original_train_rows = len(x_train)\n",
        "\n",
        "# Step 1: Filter Data Based on Ranges\n",
        "x_train_filtered, y_train_filtered, x_test_filtered, y_test_filtered, x_val_filtered, y_val_filtered = filter_data_based_on_ranges(\n",
        "    x_train, y_train, x_test, y_test, x_val, y_val, mapped_z_range, mapped_n_range\n",
        ")\n",
        "\n",
        "# Displaying the shapes of the filtered data\n",
        "print(f\"ZN Filtered Training Data: {x_train_filtered.shape}, Labels: {y_train_filtered.shape}\")\n",
        "print(f\"ZN Filtered Testing Data: {x_test_filtered.shape}, Labels: {y_test_filtered.shape}\")\n",
        "print(f\"ZN Filtered Validation Data: {x_val_filtered.shape}, Labels: {y_val_filtered.shape}\")\n",
        "\n",
        "filtered_train_rows = len(x_train_filtered)\n",
        "\n",
        "# Step 2: Apply Fraction Scaling\n",
        "x_train_scaled, y_train_scaled, x_test_scaled, y_test_scaled, x_val_scaled, y_val_scaled = apply_fraction_scaling(\n",
        "    x_train_filtered, y_train_filtered, x_test_filtered, y_test_filtered, x_val_filtered, y_val_filtered, fraction\n",
        ")\n",
        "\n",
        "# Displaying the shapes of the scaled data\n",
        "print(f\"ZNFraction Scaled Training Data: {x_train_scaled.shape}, Labels: {y_train_scaled.shape}\")\n",
        "print(f\"ZNFraction Scaled Testing Data: {x_test_scaled.shape}, Labels: {y_test_scaled.shape}\")\n",
        "print(f\"ZNFraction Scaled Validation Data: {x_val_scaled.shape}, Labels: {y_val_scaled.shape}\")\n",
        "\n",
        "scaled_train_rows = len(x_train_scaled)\n",
        "\n",
        "# Step 3: Limit Rows per Combination\n",
        "x_train_final, y_train_final, x_val_final, y_val_final, x_test_final, y_test_final = limit_rows_per_combination(\n",
        "    x_train_scaled, y_train_scaled, x_test_scaled, y_test_scaled, x_val_scaled, y_val_scaled, max_rows_per_combination_train\n",
        ")\n",
        "\n",
        "# Displaying the shapes of the final data\n",
        "print(f\"Final Training Data: {x_train_final.shape}, Labels: {y_train_final.shape}\")\n",
        "print(f\"Final Validation Data: {x_val_final.shape}, Labels: {y_val_final.shape}\")\n",
        "print(f\"Final Testing Data: {x_test_final.shape}, Labels: {y_test_final.shape}\")\n",
        "\n",
        "final_train_rows = len(x_train_final)\n",
        "\n",
        "# Plotting the reduction of x_train rows at each step\n",
        "steps = ['Original', 'Filtered', 'Scaled', 'Limited']\n",
        "rows = [original_train_rows, filtered_train_rows, scaled_train_rows, final_train_rows]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(steps, rows, marker='o')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Number of Rows')\n",
        "plt.title('Reduction of x_train Rows at Each Step')\n",
        "plt.ylim(0, original_train_rows+1e6)  # Lock the range from 0 to the maximum\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "b20yUTNHkkz_",
        "outputId": "95704928-d8ef-4b17-97a8-b4f4db1d8ce8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data (x_train): (40712, 32), Labels (y_train): (40712,)\n",
            "Validation Data (x_val): (5090, 32), Labels (y_val): (5090,)\n",
            "Testing Data (x_test): (5090, 32), Labels (y_test): (5090,)\n",
            "ZN Filtered Training Data: (40712, 32), Labels: (40712,)\n",
            "ZN Filtered Testing Data: (5090, 32), Labels: (5090,)\n",
            "ZN Filtered Validation Data: (5090, 32), Labels: (5090,)\n",
            "ZNFraction Scaled Training Data: (40712, 32), Labels: (40712,)\n",
            "ZNFraction Scaled Testing Data: (5090, 32), Labels: (5090,)\n",
            "ZNFraction Scaled Validation Data: (5090, 32), Labels: (5090,)\n",
            "Final Training Data: (40712, 32), Labels: (40712,)\n",
            "Final Validation Data: (5090, 32), Labels: (5090,)\n",
            "Final Testing Data: (5090, 32), Labels: (5090,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a list to compile all results\n",
        "all_results = []\n",
        "\n",
        "# Iterate over parameter combinations\n",
        "for i, params in enumerate(param_combinations):\n",
        "    print(f\"Training model {i + 1} with parameters: {params}\")\n",
        "\n",
        "    # Initializing the model instance with current parameters\n",
        "    dt_model = tree.DecisionTreeRegressor(**params)\n",
        "\n",
        "    # Training the model\n",
        "    print(f\"Training with x_train_final shape: {x_train_final.shape}, y_train_final shape: {y_train_final.shape}\")\n",
        "    dt_model.fit(x_train_final, y_train_final)\n",
        "\n",
        "    # Making model predictions to calculate metrics\n",
        "    y_hat_train = dt_model.predict(x_train_final)\n",
        "    y_hat_val = dt_model.predict(x_val_final)\n",
        "    y_hat_test = dt_model.predict(x_test_final)\n",
        "\n",
        "    # Output prediction stats\n",
        "    print(f\"Predictions on training data: {y_hat_train[:5]}\")\n",
        "    print(f\"Predictions on validation data: {y_hat_val[:5]}\")\n",
        "    print(f\"Predictions on testing data: {y_hat_test[:5]}\")\n",
        "\n",
        "    # Getting performance metrics using model_utils from NucML (ensure model_utils is defined/imported correctly)\n",
        "    train_error_metrics = model_utils.regression_error_metrics(y_hat_train, y_train_final)\n",
        "    val_error_metrics = model_utils.regression_error_metrics(y_hat_val, y_val_final)\n",
        "    test_error_metrics = model_utils.regression_error_metrics(y_hat_test, y_test_final)\n",
        "\n",
        "    # Specify the path and name for the model\n",
        "    model_name = f\"dt_model_{i+1}_mss{params['min_samples_split']}_msl{params['min_samples_leaf']}_maxdepth{params['max_depth']}.joblib\"\n",
        "    model_saving_path = os.path.join(model_saving_directory, model_name)\n",
        "\n",
        "    # Compile results into a dictionary\n",
        "    result = {\n",
        "        \"id\": i + 1,\n",
        "        \"max_depth\": params[\"max_depth\"],\n",
        "        \"mss\": params[\"min_samples_split\"],\n",
        "        \"msl\": params[\"min_samples_leaf\"],\n",
        "        \"normalizer\": \"standard_scaler\",\n",
        "        \"train_mae\": train_error_metrics['mae'],\n",
        "        \"train_mse\": train_error_metrics['mse'],\n",
        "        \"train_evs\": train_error_metrics['evs'],\n",
        "        \"train_r2\": train_error_metrics['r2'],\n",
        "        \"val_mae\": val_error_metrics['mae'],\n",
        "        \"val_mse\": val_error_metrics['mse'],\n",
        "        \"val_evs\": val_error_metrics['evs'],\n",
        "        \"val_r2\": val_error_metrics['r2'],\n",
        "        \"test_mae\": test_error_metrics['mae'],\n",
        "        \"test_mse\": test_error_metrics['mse'],\n",
        "        \"test_evs\": test_error_metrics['evs'],\n",
        "        \"test_r2\": test_error_metrics['r2'],\n",
        "        \"model_path\": os.path.abspath(model_saving_path),\n",
        "        \"scaler_path\": os.path.abspath(scaler_saving_path)\n",
        "    }\n",
        "\n",
        "    # Ensure the directory exists\n",
        "    os.makedirs(os.path.dirname(model_saving_path), exist_ok=True)\n",
        "\n",
        "    # Save the model\n",
        "    dump(dt_model, model_saving_path)\n",
        "\n",
        "    # Append the results to the list\n",
        "    all_results.append(result)\n",
        "\n",
        "    print(f\"Results saved for model {i + 1}\")\n",
        "\n",
        "# Convert the list of results to a DataFrame and reorder columns\n",
        "required_columns = [\"id\", \"max_depth\", \"mss\", \"msl\", \"normalizer\", \"train_mae\", \"train_mse\", \"train_evs\", \"train_r2\",\n",
        "                    \"val_mae\", \"val_mse\", \"val_evs\", \"val_r2\", \"test_mae\", \"test_mse\", \"test_evs\", \"test_r2\",\n",
        "                    \"model_path\", \"scaler_path\"]\n",
        "results_df = pd.DataFrame(all_results)\n",
        "results_df = results_df[required_columns]\n",
        "\n",
        "# Save as a CSV file with the specified filename\n",
        "all_results_filepath = os.path.join(model_saving_directory, all_results_filename)\n",
        "results_df.to_csv(all_results_filepath, index=False)\n",
        "\n",
        "print(f\"All results compiled and saved to {all_results_filepath}\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "display(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e3ddc246-fd77-43f3-d59c-9f6824c0cfa8",
        "id": "PVch-ZWziGqY"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model 1 with parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.86365072 -7.08271636 -7.41066696 -7.60676989 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8922559  -5.07280293 -8.74714413 -5.07755151 -1.53652738]\n",
            "Results saved for model 1\n",
            "Training model 2 with parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.94346201 -7.10559522 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.53652738]\n",
            "Results saved for model 2\n",
            "Training model 3 with parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.53652738]\n",
            "Results saved for model 3\n",
            "Training model 4 with parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.53652738]\n",
            "Results saved for model 4\n",
            "Training model 5 with parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.53652738]\n",
            "Results saved for model 5\n",
            "Training model 6 with parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.53652738]\n",
            "Results saved for model 6\n",
            "Training model 7 with parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.53652738]\n",
            "Results saved for model 7\n",
            "Training model 8 with parameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.86365072 -7.08271636 -7.41066696 -7.60676989 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8922559  -5.07280293 -8.74714413 -5.07755151 -1.53652738]\n",
            "Results saved for model 8\n",
            "Training model 9 with parameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.94346201 -7.10559522 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.53652738]\n",
            "Results saved for model 9\n",
            "Training model 10 with parameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.53652738]\n",
            "Results saved for model 10\n",
            "Training model 11 with parameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.53652738]\n",
            "Results saved for model 11\n",
            "Training model 12 with parameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.53652738]\n",
            "Results saved for model 12\n",
            "Training model 13 with parameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.53652738]\n",
            "Results saved for model 13\n",
            "Training model 14 with parameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.53652738]\n",
            "Results saved for model 14\n",
            "Training model 15 with parameters: {'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.86365072 -7.08271636 -7.41066696 -7.60676989 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8922559  -5.07280293 -8.74714413 -5.07755151 -1.53652738]\n",
            "Results saved for model 15\n",
            "Training model 16 with parameters: {'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.94346201 -7.10559522 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.53652738]\n",
            "Results saved for model 16\n",
            "Training model 17 with parameters: {'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.53652738]\n",
            "Results saved for model 17\n",
            "Training model 18 with parameters: {'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.53652738]\n",
            "Results saved for model 18\n",
            "Training model 19 with parameters: {'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.53652738]\n",
            "Results saved for model 19\n",
            "Training model 20 with parameters: {'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.53652738]\n",
            "Results saved for model 20\n",
            "Training model 21 with parameters: {'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.53652738]\n",
            "Results saved for model 21\n",
            "Training model 22 with parameters: {'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.86365072 -7.08271636 -7.41066696 -7.60676989 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8922559  -5.07280293 -8.74714413 -5.07072503 -1.53652738]\n",
            "Results saved for model 22\n",
            "Training model 23 with parameters: {'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.94346201 -7.10559522 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.53652738]\n",
            "Results saved for model 23\n",
            "Training model 24 with parameters: {'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.53652738]\n",
            "Results saved for model 24\n",
            "Training model 25 with parameters: {'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.53652738]\n",
            "Results saved for model 25\n",
            "Training model 26 with parameters: {'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.53652738]\n",
            "Results saved for model 26\n",
            "Training model 27 with parameters: {'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.53652738]\n",
            "Results saved for model 27\n",
            "Training model 28 with parameters: {'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.53652738]\n",
            "Results saved for model 28\n",
            "Training model 29 with parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.86365072 -7.08271636 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8922559  -5.07280293 -8.74714413 -5.07072503 -1.53652738]\n",
            "Results saved for model 29\n",
            "Training model 30 with parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.94346201 -7.10559522 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.53652738]\n",
            "Results saved for model 30\n",
            "Training model 31 with parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.53652738]\n",
            "Results saved for model 31\n",
            "Training model 32 with parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.53652738]\n",
            "Results saved for model 32\n",
            "Training model 33 with parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.53652738]\n",
            "Results saved for model 33\n",
            "Training model 34 with parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.53652738]\n",
            "Results saved for model 34\n",
            "Training model 35 with parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.53652738]\n",
            "Results saved for model 35\n",
            "Training model 36 with parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.86365072 -7.01922954 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -7.01922954 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.74714413 -5.07072503 -1.53652738]\n",
            "Results saved for model 36\n",
            "Training model 37 with parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.94346201 -7.01922954 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -7.01922954 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.79099878 -5.07072503 -1.53652738]\n",
            "Results saved for model 37\n",
            "Training model 38 with parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.53652738]\n",
            "Results saved for model 38\n",
            "Training model 39 with parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.53652738]\n",
            "Results saved for model 39\n",
            "Training model 40 with parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.53652738]\n",
            "Results saved for model 40\n",
            "Training model 41 with parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.53652738]\n",
            "Results saved for model 41\n",
            "Training model 42 with parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.53652738]\n",
            "Results saved for model 42\n",
            "Training model 43 with parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.86365072 -7.01922954 -7.4774067  -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -7.01922954 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.74714413 -4.43396504 -1.53652738]\n",
            "Results saved for model 43\n",
            "Training model 44 with parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.94346201 -7.01922954 -7.4774067  -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -7.01922954 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.79099878 -4.43396504 -1.53652738]\n",
            "Results saved for model 44\n",
            "Training model 45 with parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.53652738]\n",
            "Results saved for model 45\n",
            "Training model 46 with parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.53652738]\n",
            "Results saved for model 46\n",
            "Training model 47 with parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.53652738]\n",
            "Results saved for model 47\n",
            "Training model 48 with parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.53652738]\n",
            "Results saved for model 48\n",
            "Training model 49 with parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.00170451 -1.53652738]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.53652738]\n",
            "Results saved for model 49\n",
            "Training model 50 with parameters: {'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 50\n",
            "Training model 51 with parameters: {'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 51\n",
            "Training model 52 with parameters: {'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 52\n",
            "Training model 53 with parameters: {'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 53\n",
            "Training model 54 with parameters: {'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 54\n",
            "Training model 55 with parameters: {'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 55\n",
            "Training model 56 with parameters: {'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 56\n",
            "Training model 57 with parameters: {'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 57\n",
            "Training model 58 with parameters: {'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 58\n",
            "Training model 59 with parameters: {'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 59\n",
            "Training model 60 with parameters: {'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 60\n",
            "Training model 61 with parameters: {'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 61\n",
            "Training model 62 with parameters: {'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 62\n",
            "Training model 63 with parameters: {'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 63\n",
            "Training model 64 with parameters: {'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 64\n",
            "Training model 65 with parameters: {'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 65\n",
            "Training model 66 with parameters: {'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 66\n",
            "Training model 67 with parameters: {'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 67\n",
            "Training model 68 with parameters: {'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 68\n",
            "Training model 69 with parameters: {'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 69\n",
            "Training model 70 with parameters: {'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 70\n",
            "Training model 71 with parameters: {'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.08271636 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07072503 -1.14592184]\n",
            "Results saved for model 71\n",
            "Training model 72 with parameters: {'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 72\n",
            "Training model 73 with parameters: {'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 73\n",
            "Training model 74 with parameters: {'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 74\n",
            "Training model 75 with parameters: {'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 75\n",
            "Training model 76 with parameters: {'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 76\n",
            "Training model 77 with parameters: {'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 77\n",
            "Training model 78 with parameters: {'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.08271636 -7.41066696 -7.65700311 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.29404336 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.07280293 -8.74714413 -5.07072503 -1.12516302]\n",
            "Results saved for model 78\n",
            "Training model 79 with parameters: {'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 79\n",
            "Training model 80 with parameters: {'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 80\n",
            "Training model 81 with parameters: {'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 81\n",
            "Training model 82 with parameters: {'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 82\n",
            "Training model 83 with parameters: {'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 83\n",
            "Training model 84 with parameters: {'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 84\n",
            "Training model 85 with parameters: {'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.01922954 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -7.01922954 -7.29404336 -2.63252012 -1.03961234]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.74714413 -5.07072503 -1.12516302]\n",
            "Results saved for model 85\n",
            "Training model 86 with parameters: {'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.01922954 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -7.01922954 -7.29404336 -1.01310533 -1.03753959]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 86\n",
            "Training model 87 with parameters: {'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 87\n",
            "Training model 88 with parameters: {'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 88\n",
            "Training model 89 with parameters: {'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 89\n",
            "Training model 90 with parameters: {'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 90\n",
            "Training model 91 with parameters: {'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 91\n",
            "Training model 92 with parameters: {'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.01922954 -7.4774067  -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -7.01922954 -7.29404336 -2.63252012 -1.03961234]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.74714413 -4.43396504 -1.12516302]\n",
            "Results saved for model 92\n",
            "Training model 93 with parameters: {'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.01922954 -7.4774067  -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -7.01922954 -7.29404336 -1.01310533 -1.03753959]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.79099878 -4.43396504 -1.12516302]\n",
            "Results saved for model 93\n",
            "Training model 94 with parameters: {'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 94\n",
            "Training model 95 with parameters: {'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 95\n",
            "Training model 96 with parameters: {'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 96\n",
            "Training model 97 with parameters: {'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 97\n",
            "Training model 98 with parameters: {'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 98\n",
            "Training model 99 with parameters: {'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 99\n",
            "Training model 100 with parameters: {'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 100\n",
            "Training model 101 with parameters: {'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 101\n",
            "Training model 102 with parameters: {'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 102\n",
            "Training model 103 with parameters: {'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 103\n",
            "Training model 104 with parameters: {'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 104\n",
            "Training model 105 with parameters: {'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 105\n",
            "Training model 106 with parameters: {'max_depth': 50, 'min_samples_split': 3, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 106\n",
            "Training model 107 with parameters: {'max_depth': 50, 'min_samples_split': 3, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 107\n",
            "Training model 108 with parameters: {'max_depth': 50, 'min_samples_split': 3, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 108\n",
            "Training model 109 with parameters: {'max_depth': 50, 'min_samples_split': 3, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 109\n",
            "Training model 110 with parameters: {'max_depth': 50, 'min_samples_split': 3, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 110\n",
            "Training model 111 with parameters: {'max_depth': 50, 'min_samples_split': 3, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 111\n",
            "Training model 112 with parameters: {'max_depth': 50, 'min_samples_split': 3, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 112\n",
            "Training model 113 with parameters: {'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 113\n",
            "Training model 114 with parameters: {'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 114\n",
            "Training model 115 with parameters: {'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 115\n",
            "Training model 116 with parameters: {'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 116\n",
            "Training model 117 with parameters: {'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 117\n",
            "Training model 118 with parameters: {'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 118\n",
            "Training model 119 with parameters: {'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 119\n",
            "Training model 120 with parameters: {'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.08271636 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07072503 -1.14592184]\n",
            "Results saved for model 120\n",
            "Training model 121 with parameters: {'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 121\n",
            "Training model 122 with parameters: {'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 122\n",
            "Training model 123 with parameters: {'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 123\n",
            "Training model 124 with parameters: {'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 124\n",
            "Training model 125 with parameters: {'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 125\n",
            "Training model 126 with parameters: {'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 126\n",
            "Training model 127 with parameters: {'max_depth': 50, 'min_samples_split': 6, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.08271636 -7.41066696 -7.65700311 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.29404336 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.07280293 -8.74714413 -5.07072503 -1.12516302]\n",
            "Results saved for model 127\n",
            "Training model 128 with parameters: {'max_depth': 50, 'min_samples_split': 6, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 128\n",
            "Training model 129 with parameters: {'max_depth': 50, 'min_samples_split': 6, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 129\n",
            "Training model 130 with parameters: {'max_depth': 50, 'min_samples_split': 6, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 130\n",
            "Training model 131 with parameters: {'max_depth': 50, 'min_samples_split': 6, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 131\n",
            "Training model 132 with parameters: {'max_depth': 50, 'min_samples_split': 6, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 132\n",
            "Training model 133 with parameters: {'max_depth': 50, 'min_samples_split': 6, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 133\n",
            "Training model 134 with parameters: {'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.01922954 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -7.01922954 -7.29404336 -2.63252012 -1.03961234]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.74714413 -5.07072503 -1.12516302]\n",
            "Results saved for model 134\n",
            "Training model 135 with parameters: {'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.01922954 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -7.01922954 -7.29404336 -1.01310533 -1.03753959]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 135\n",
            "Training model 136 with parameters: {'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 136\n",
            "Training model 137 with parameters: {'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 137\n",
            "Training model 138 with parameters: {'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 138\n",
            "Training model 139 with parameters: {'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 139\n",
            "Training model 140 with parameters: {'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 140\n",
            "Training model 141 with parameters: {'max_depth': 50, 'min_samples_split': 8, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.01922954 -7.4774067  -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -7.01922954 -7.29404336 -2.63252012 -1.03961234]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.74714413 -4.43396504 -1.12516302]\n",
            "Results saved for model 141\n",
            "Training model 142 with parameters: {'max_depth': 50, 'min_samples_split': 8, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.01922954 -7.4774067  -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -7.01922954 -7.29404336 -1.01310533 -1.03753959]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.79099878 -4.43396504 -1.12516302]\n",
            "Results saved for model 142\n",
            "Training model 143 with parameters: {'max_depth': 50, 'min_samples_split': 8, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 143\n",
            "Training model 144 with parameters: {'max_depth': 50, 'min_samples_split': 8, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 144\n",
            "Training model 145 with parameters: {'max_depth': 50, 'min_samples_split': 8, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 145\n",
            "Training model 146 with parameters: {'max_depth': 50, 'min_samples_split': 8, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 146\n",
            "Training model 147 with parameters: {'max_depth': 50, 'min_samples_split': 8, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 147\n",
            "Training model 148 with parameters: {'max_depth': 70, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 148\n",
            "Training model 149 with parameters: {'max_depth': 70, 'min_samples_split': 2, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 149\n",
            "Training model 150 with parameters: {'max_depth': 70, 'min_samples_split': 2, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 150\n",
            "Training model 151 with parameters: {'max_depth': 70, 'min_samples_split': 2, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 151\n",
            "Training model 152 with parameters: {'max_depth': 70, 'min_samples_split': 2, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 152\n",
            "Training model 153 with parameters: {'max_depth': 70, 'min_samples_split': 2, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 153\n",
            "Training model 154 with parameters: {'max_depth': 70, 'min_samples_split': 2, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 154\n",
            "Training model 155 with parameters: {'max_depth': 70, 'min_samples_split': 3, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 155\n",
            "Training model 156 with parameters: {'max_depth': 70, 'min_samples_split': 3, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 156\n",
            "Training model 157 with parameters: {'max_depth': 70, 'min_samples_split': 3, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 157\n",
            "Training model 158 with parameters: {'max_depth': 70, 'min_samples_split': 3, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 158\n",
            "Training model 159 with parameters: {'max_depth': 70, 'min_samples_split': 3, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 159\n",
            "Training model 160 with parameters: {'max_depth': 70, 'min_samples_split': 3, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 160\n",
            "Training model 161 with parameters: {'max_depth': 70, 'min_samples_split': 3, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 161\n",
            "Training model 162 with parameters: {'max_depth': 70, 'min_samples_split': 4, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 162\n",
            "Training model 163 with parameters: {'max_depth': 70, 'min_samples_split': 4, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 163\n",
            "Training model 164 with parameters: {'max_depth': 70, 'min_samples_split': 4, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 164\n",
            "Training model 165 with parameters: {'max_depth': 70, 'min_samples_split': 4, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 165\n",
            "Training model 166 with parameters: {'max_depth': 70, 'min_samples_split': 4, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 166\n",
            "Training model 167 with parameters: {'max_depth': 70, 'min_samples_split': 4, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 167\n",
            "Training model 168 with parameters: {'max_depth': 70, 'min_samples_split': 4, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 168\n",
            "Training model 169 with parameters: {'max_depth': 70, 'min_samples_split': 5, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.08271636 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07072503 -1.14592184]\n",
            "Results saved for model 169\n",
            "Training model 170 with parameters: {'max_depth': 70, 'min_samples_split': 5, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 170\n",
            "Training model 171 with parameters: {'max_depth': 70, 'min_samples_split': 5, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 171\n",
            "Training model 172 with parameters: {'max_depth': 70, 'min_samples_split': 5, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 172\n",
            "Training model 173 with parameters: {'max_depth': 70, 'min_samples_split': 5, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 173\n",
            "Training model 174 with parameters: {'max_depth': 70, 'min_samples_split': 5, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 174\n",
            "Training model 175 with parameters: {'max_depth': 70, 'min_samples_split': 5, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 175\n",
            "Training model 176 with parameters: {'max_depth': 70, 'min_samples_split': 6, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.08271636 -7.41066696 -7.65700311 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.29404336 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.07280293 -8.74714413 -5.07072503 -1.12516302]\n",
            "Results saved for model 176\n",
            "Training model 177 with parameters: {'max_depth': 70, 'min_samples_split': 6, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 177\n",
            "Training model 178 with parameters: {'max_depth': 70, 'min_samples_split': 6, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 178\n",
            "Training model 179 with parameters: {'max_depth': 70, 'min_samples_split': 6, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 179\n",
            "Training model 180 with parameters: {'max_depth': 70, 'min_samples_split': 6, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 180\n",
            "Training model 181 with parameters: {'max_depth': 70, 'min_samples_split': 6, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 181\n",
            "Training model 182 with parameters: {'max_depth': 70, 'min_samples_split': 6, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 182\n",
            "Training model 183 with parameters: {'max_depth': 70, 'min_samples_split': 7, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.01922954 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -7.01922954 -7.29404336 -2.63252012 -1.03961234]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.74714413 -5.07072503 -1.12516302]\n",
            "Results saved for model 183\n",
            "Training model 184 with parameters: {'max_depth': 70, 'min_samples_split': 7, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.01922954 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -7.01922954 -7.29404336 -1.01310533 -1.03753959]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 184\n",
            "Training model 185 with parameters: {'max_depth': 70, 'min_samples_split': 7, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 185\n",
            "Training model 186 with parameters: {'max_depth': 70, 'min_samples_split': 7, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 186\n",
            "Training model 187 with parameters: {'max_depth': 70, 'min_samples_split': 7, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 187\n",
            "Training model 188 with parameters: {'max_depth': 70, 'min_samples_split': 7, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 188\n",
            "Training model 189 with parameters: {'max_depth': 70, 'min_samples_split': 7, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 189\n",
            "Training model 190 with parameters: {'max_depth': 70, 'min_samples_split': 8, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.01922954 -7.4774067  -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -7.01922954 -7.29404336 -2.63252012 -1.03961234]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.74714413 -4.43396504 -1.12516302]\n",
            "Results saved for model 190\n",
            "Training model 191 with parameters: {'max_depth': 70, 'min_samples_split': 8, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.01922954 -7.4774067  -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -7.01922954 -7.29404336 -1.01310533 -1.03753959]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.79099878 -4.43396504 -1.12516302]\n",
            "Results saved for model 191\n",
            "Training model 192 with parameters: {'max_depth': 70, 'min_samples_split': 8, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 192\n",
            "Training model 193 with parameters: {'max_depth': 70, 'min_samples_split': 8, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 193\n",
            "Training model 194 with parameters: {'max_depth': 70, 'min_samples_split': 8, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 194\n",
            "Training model 195 with parameters: {'max_depth': 70, 'min_samples_split': 8, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 195\n",
            "Training model 196 with parameters: {'max_depth': 70, 'min_samples_split': 8, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 196\n",
            "Training model 197 with parameters: {'max_depth': 76, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 197\n",
            "Training model 198 with parameters: {'max_depth': 76, 'min_samples_split': 2, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 198\n",
            "Training model 199 with parameters: {'max_depth': 76, 'min_samples_split': 2, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 199\n",
            "Training model 200 with parameters: {'max_depth': 76, 'min_samples_split': 2, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 200\n",
            "Training model 201 with parameters: {'max_depth': 76, 'min_samples_split': 2, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 201\n",
            "Training model 202 with parameters: {'max_depth': 76, 'min_samples_split': 2, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 202\n",
            "Training model 203 with parameters: {'max_depth': 76, 'min_samples_split': 2, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 203\n",
            "Training model 204 with parameters: {'max_depth': 76, 'min_samples_split': 3, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 204\n",
            "Training model 205 with parameters: {'max_depth': 76, 'min_samples_split': 3, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 205\n",
            "Training model 206 with parameters: {'max_depth': 76, 'min_samples_split': 3, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 206\n",
            "Training model 207 with parameters: {'max_depth': 76, 'min_samples_split': 3, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 207\n",
            "Training model 208 with parameters: {'max_depth': 76, 'min_samples_split': 3, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 208\n",
            "Training model 209 with parameters: {'max_depth': 76, 'min_samples_split': 3, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 209\n",
            "Training model 210 with parameters: {'max_depth': 76, 'min_samples_split': 3, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 210\n",
            "Training model 211 with parameters: {'max_depth': 76, 'min_samples_split': 4, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 211\n",
            "Training model 212 with parameters: {'max_depth': 76, 'min_samples_split': 4, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 212\n",
            "Training model 213 with parameters: {'max_depth': 76, 'min_samples_split': 4, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 213\n",
            "Training model 214 with parameters: {'max_depth': 76, 'min_samples_split': 4, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 214\n",
            "Training model 215 with parameters: {'max_depth': 76, 'min_samples_split': 4, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 215\n",
            "Training model 216 with parameters: {'max_depth': 76, 'min_samples_split': 4, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 216\n",
            "Training model 217 with parameters: {'max_depth': 76, 'min_samples_split': 4, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 217\n",
            "Training model 218 with parameters: {'max_depth': 76, 'min_samples_split': 5, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.08271636 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07072503 -1.14592184]\n",
            "Results saved for model 218\n",
            "Training model 219 with parameters: {'max_depth': 76, 'min_samples_split': 5, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 219\n",
            "Training model 220 with parameters: {'max_depth': 76, 'min_samples_split': 5, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 220\n",
            "Training model 221 with parameters: {'max_depth': 76, 'min_samples_split': 5, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 221\n",
            "Training model 222 with parameters: {'max_depth': 76, 'min_samples_split': 5, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 222\n",
            "Training model 223 with parameters: {'max_depth': 76, 'min_samples_split': 5, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 223\n",
            "Training model 224 with parameters: {'max_depth': 76, 'min_samples_split': 5, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 224\n",
            "Training model 225 with parameters: {'max_depth': 76, 'min_samples_split': 6, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.08271636 -7.41066696 -7.65700311 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.29404336 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.07280293 -8.74714413 -5.07072503 -1.12516302]\n",
            "Results saved for model 225\n",
            "Training model 226 with parameters: {'max_depth': 76, 'min_samples_split': 6, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 226\n",
            "Training model 227 with parameters: {'max_depth': 76, 'min_samples_split': 6, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 227\n",
            "Training model 228 with parameters: {'max_depth': 76, 'min_samples_split': 6, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 228\n",
            "Training model 229 with parameters: {'max_depth': 76, 'min_samples_split': 6, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 229\n",
            "Training model 230 with parameters: {'max_depth': 76, 'min_samples_split': 6, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 230\n",
            "Training model 231 with parameters: {'max_depth': 76, 'min_samples_split': 6, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 231\n",
            "Training model 232 with parameters: {'max_depth': 76, 'min_samples_split': 7, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.01922954 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -7.01922954 -7.29404336 -2.63252012 -1.03961234]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.74714413 -5.07072503 -1.12516302]\n",
            "Results saved for model 232\n",
            "Training model 233 with parameters: {'max_depth': 76, 'min_samples_split': 7, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.01922954 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -7.01922954 -7.29404336 -1.01310533 -1.03753959]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 233\n",
            "Training model 234 with parameters: {'max_depth': 76, 'min_samples_split': 7, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 234\n",
            "Training model 235 with parameters: {'max_depth': 76, 'min_samples_split': 7, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 235\n",
            "Training model 236 with parameters: {'max_depth': 76, 'min_samples_split': 7, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 236\n",
            "Training model 237 with parameters: {'max_depth': 76, 'min_samples_split': 7, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 237\n",
            "Training model 238 with parameters: {'max_depth': 76, 'min_samples_split': 7, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 238\n",
            "Training model 239 with parameters: {'max_depth': 76, 'min_samples_split': 8, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.01922954 -7.4774067  -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -7.01922954 -7.29404336 -2.63252012 -1.03961234]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.74714413 -4.43396504 -1.12516302]\n",
            "Results saved for model 239\n",
            "Training model 240 with parameters: {'max_depth': 76, 'min_samples_split': 8, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.01922954 -7.4774067  -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -7.01922954 -7.29404336 -1.01310533 -1.03753959]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.79099878 -4.43396504 -1.12516302]\n",
            "Results saved for model 240\n",
            "Training model 241 with parameters: {'max_depth': 76, 'min_samples_split': 8, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 241\n",
            "Training model 242 with parameters: {'max_depth': 76, 'min_samples_split': 8, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 242\n",
            "Training model 243 with parameters: {'max_depth': 76, 'min_samples_split': 8, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 243\n",
            "Training model 244 with parameters: {'max_depth': 76, 'min_samples_split': 8, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 244\n",
            "Training model 245 with parameters: {'max_depth': 76, 'min_samples_split': 8, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 245\n",
            "Training model 246 with parameters: {'max_depth': 82, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 246\n",
            "Training model 247 with parameters: {'max_depth': 82, 'min_samples_split': 2, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 247\n",
            "Training model 248 with parameters: {'max_depth': 82, 'min_samples_split': 2, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 248\n",
            "Training model 249 with parameters: {'max_depth': 82, 'min_samples_split': 2, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 249\n",
            "Training model 250 with parameters: {'max_depth': 82, 'min_samples_split': 2, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 250\n",
            "Training model 251 with parameters: {'max_depth': 82, 'min_samples_split': 2, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 251\n",
            "Training model 252 with parameters: {'max_depth': 82, 'min_samples_split': 2, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 252\n",
            "Training model 253 with parameters: {'max_depth': 82, 'min_samples_split': 3, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 253\n",
            "Training model 254 with parameters: {'max_depth': 82, 'min_samples_split': 3, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 254\n",
            "Training model 255 with parameters: {'max_depth': 82, 'min_samples_split': 3, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 255\n",
            "Training model 256 with parameters: {'max_depth': 82, 'min_samples_split': 3, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 256\n",
            "Training model 257 with parameters: {'max_depth': 82, 'min_samples_split': 3, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 257\n",
            "Training model 258 with parameters: {'max_depth': 82, 'min_samples_split': 3, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 258\n",
            "Training model 259 with parameters: {'max_depth': 82, 'min_samples_split': 3, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 259\n",
            "Training model 260 with parameters: {'max_depth': 82, 'min_samples_split': 4, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 260\n",
            "Training model 261 with parameters: {'max_depth': 82, 'min_samples_split': 4, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 261\n",
            "Training model 262 with parameters: {'max_depth': 82, 'min_samples_split': 4, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 262\n",
            "Training model 263 with parameters: {'max_depth': 82, 'min_samples_split': 4, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 263\n",
            "Training model 264 with parameters: {'max_depth': 82, 'min_samples_split': 4, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 264\n",
            "Training model 265 with parameters: {'max_depth': 82, 'min_samples_split': 4, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 265\n",
            "Training model 266 with parameters: {'max_depth': 82, 'min_samples_split': 4, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 266\n",
            "Training model 267 with parameters: {'max_depth': 82, 'min_samples_split': 5, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.08271636 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07072503 -1.14592184]\n",
            "Results saved for model 267\n",
            "Training model 268 with parameters: {'max_depth': 82, 'min_samples_split': 5, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 268\n",
            "Training model 269 with parameters: {'max_depth': 82, 'min_samples_split': 5, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 269\n",
            "Training model 270 with parameters: {'max_depth': 82, 'min_samples_split': 5, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 270\n",
            "Training model 271 with parameters: {'max_depth': 82, 'min_samples_split': 5, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 271\n",
            "Training model 272 with parameters: {'max_depth': 82, 'min_samples_split': 5, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 272\n",
            "Training model 273 with parameters: {'max_depth': 82, 'min_samples_split': 5, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 273\n",
            "Training model 274 with parameters: {'max_depth': 82, 'min_samples_split': 6, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.08271636 -7.41066696 -7.65700311 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.29404336 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.07280293 -8.74714413 -5.07072503 -1.12516302]\n",
            "Results saved for model 274\n",
            "Training model 275 with parameters: {'max_depth': 82, 'min_samples_split': 6, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 275\n",
            "Training model 276 with parameters: {'max_depth': 82, 'min_samples_split': 6, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 276\n",
            "Training model 277 with parameters: {'max_depth': 82, 'min_samples_split': 6, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 277\n",
            "Training model 278 with parameters: {'max_depth': 82, 'min_samples_split': 6, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 278\n",
            "Training model 279 with parameters: {'max_depth': 82, 'min_samples_split': 6, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 279\n",
            "Training model 280 with parameters: {'max_depth': 82, 'min_samples_split': 6, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 280\n",
            "Training model 281 with parameters: {'max_depth': 82, 'min_samples_split': 7, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.01922954 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -7.01922954 -7.29404336 -2.63252012 -1.03961234]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.74714413 -5.07072503 -1.12516302]\n",
            "Results saved for model 281\n",
            "Training model 282 with parameters: {'max_depth': 82, 'min_samples_split': 7, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.01922954 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -7.01922954 -7.29404336 -1.01310533 -1.03753959]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 282\n",
            "Training model 283 with parameters: {'max_depth': 82, 'min_samples_split': 7, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 283\n",
            "Training model 284 with parameters: {'max_depth': 82, 'min_samples_split': 7, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 284\n",
            "Training model 285 with parameters: {'max_depth': 82, 'min_samples_split': 7, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 285\n",
            "Training model 286 with parameters: {'max_depth': 82, 'min_samples_split': 7, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 286\n",
            "Training model 287 with parameters: {'max_depth': 82, 'min_samples_split': 7, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 287\n",
            "Training model 288 with parameters: {'max_depth': 82, 'min_samples_split': 8, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.01922954 -7.4774067  -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -7.01922954 -7.29404336 -2.63252012 -1.03961234]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.74714413 -4.43396504 -1.12516302]\n",
            "Results saved for model 288\n",
            "Training model 289 with parameters: {'max_depth': 82, 'min_samples_split': 8, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.01922954 -7.4774067  -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -7.01922954 -7.29404336 -1.01310533 -1.03753959]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.79099878 -4.43396504 -1.12516302]\n",
            "Results saved for model 289\n",
            "Training model 290 with parameters: {'max_depth': 82, 'min_samples_split': 8, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 290\n",
            "Training model 291 with parameters: {'max_depth': 82, 'min_samples_split': 8, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 291\n",
            "Training model 292 with parameters: {'max_depth': 82, 'min_samples_split': 8, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 292\n",
            "Training model 293 with parameters: {'max_depth': 82, 'min_samples_split': 8, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 293\n",
            "Training model 294 with parameters: {'max_depth': 82, 'min_samples_split': 8, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 294\n",
            "Training model 295 with parameters: {'max_depth': 88, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 295\n",
            "Training model 296 with parameters: {'max_depth': 88, 'min_samples_split': 2, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 296\n",
            "Training model 297 with parameters: {'max_depth': 88, 'min_samples_split': 2, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 297\n",
            "Training model 298 with parameters: {'max_depth': 88, 'min_samples_split': 2, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 298\n",
            "Training model 299 with parameters: {'max_depth': 88, 'min_samples_split': 2, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 299\n",
            "Training model 300 with parameters: {'max_depth': 88, 'min_samples_split': 2, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 300\n",
            "Training model 301 with parameters: {'max_depth': 88, 'min_samples_split': 2, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 301\n",
            "Training model 302 with parameters: {'max_depth': 88, 'min_samples_split': 3, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 302\n",
            "Training model 303 with parameters: {'max_depth': 88, 'min_samples_split': 3, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 303\n",
            "Training model 304 with parameters: {'max_depth': 88, 'min_samples_split': 3, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 304\n",
            "Training model 305 with parameters: {'max_depth': 88, 'min_samples_split': 3, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 305\n",
            "Training model 306 with parameters: {'max_depth': 88, 'min_samples_split': 3, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 306\n",
            "Training model 307 with parameters: {'max_depth': 88, 'min_samples_split': 3, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 307\n",
            "Training model 308 with parameters: {'max_depth': 88, 'min_samples_split': 3, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 308\n",
            "Training model 309 with parameters: {'max_depth': 88, 'min_samples_split': 4, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 309\n",
            "Training model 310 with parameters: {'max_depth': 88, 'min_samples_split': 4, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 310\n",
            "Training model 311 with parameters: {'max_depth': 88, 'min_samples_split': 4, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 311\n",
            "Training model 312 with parameters: {'max_depth': 88, 'min_samples_split': 4, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 312\n",
            "Training model 313 with parameters: {'max_depth': 88, 'min_samples_split': 4, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 313\n",
            "Training model 314 with parameters: {'max_depth': 88, 'min_samples_split': 4, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 314\n",
            "Training model 315 with parameters: {'max_depth': 88, 'min_samples_split': 4, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 315\n",
            "Training model 316 with parameters: {'max_depth': 88, 'min_samples_split': 5, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.08271636 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07072503 -1.14592184]\n",
            "Results saved for model 316\n",
            "Training model 317 with parameters: {'max_depth': 88, 'min_samples_split': 5, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 317\n",
            "Training model 318 with parameters: {'max_depth': 88, 'min_samples_split': 5, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 318\n",
            "Training model 319 with parameters: {'max_depth': 88, 'min_samples_split': 5, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 319\n",
            "Training model 320 with parameters: {'max_depth': 88, 'min_samples_split': 5, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 320\n",
            "Training model 321 with parameters: {'max_depth': 88, 'min_samples_split': 5, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 321\n",
            "Training model 322 with parameters: {'max_depth': 88, 'min_samples_split': 5, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 322\n",
            "Training model 323 with parameters: {'max_depth': 88, 'min_samples_split': 6, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.08271636 -7.41066696 -7.65700311 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.29404336 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.07280293 -8.74714413 -5.07072503 -1.12516302]\n",
            "Results saved for model 323\n",
            "Training model 324 with parameters: {'max_depth': 88, 'min_samples_split': 6, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 324\n",
            "Training model 325 with parameters: {'max_depth': 88, 'min_samples_split': 6, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 325\n",
            "Training model 326 with parameters: {'max_depth': 88, 'min_samples_split': 6, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 326\n",
            "Training model 327 with parameters: {'max_depth': 88, 'min_samples_split': 6, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 327\n",
            "Training model 328 with parameters: {'max_depth': 88, 'min_samples_split': 6, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 328\n",
            "Training model 329 with parameters: {'max_depth': 88, 'min_samples_split': 6, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 329\n",
            "Training model 330 with parameters: {'max_depth': 88, 'min_samples_split': 7, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.01922954 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -7.01922954 -7.29404336 -2.63252012 -1.03961234]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.74714413 -5.07072503 -1.12516302]\n",
            "Results saved for model 330\n",
            "Training model 331 with parameters: {'max_depth': 88, 'min_samples_split': 7, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.01922954 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -7.01922954 -7.29404336 -1.01310533 -1.03753959]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 331\n",
            "Training model 332 with parameters: {'max_depth': 88, 'min_samples_split': 7, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 332\n",
            "Training model 333 with parameters: {'max_depth': 88, 'min_samples_split': 7, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 333\n",
            "Training model 334 with parameters: {'max_depth': 88, 'min_samples_split': 7, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 334\n",
            "Training model 335 with parameters: {'max_depth': 88, 'min_samples_split': 7, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 335\n",
            "Training model 336 with parameters: {'max_depth': 88, 'min_samples_split': 7, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 336\n",
            "Training model 337 with parameters: {'max_depth': 88, 'min_samples_split': 8, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.01922954 -7.4774067  -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -7.01922954 -7.29404336 -2.63252012 -1.03961234]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.74714413 -4.43396504 -1.12516302]\n",
            "Results saved for model 337\n",
            "Training model 338 with parameters: {'max_depth': 88, 'min_samples_split': 8, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.01922954 -7.4774067  -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -7.01922954 -7.29404336 -1.01310533 -1.03753959]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.79099878 -4.43396504 -1.12516302]\n",
            "Results saved for model 338\n",
            "Training model 339 with parameters: {'max_depth': 88, 'min_samples_split': 8, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 339\n",
            "Training model 340 with parameters: {'max_depth': 88, 'min_samples_split': 8, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 340\n",
            "Training model 341 with parameters: {'max_depth': 88, 'min_samples_split': 8, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 341\n",
            "Training model 342 with parameters: {'max_depth': 88, 'min_samples_split': 8, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 342\n",
            "Training model 343 with parameters: {'max_depth': 88, 'min_samples_split': 8, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 343\n",
            "Training model 344 with parameters: {'max_depth': 150, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 344\n",
            "Training model 345 with parameters: {'max_depth': 150, 'min_samples_split': 2, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 345\n",
            "Training model 346 with parameters: {'max_depth': 150, 'min_samples_split': 2, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 346\n",
            "Training model 347 with parameters: {'max_depth': 150, 'min_samples_split': 2, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 347\n",
            "Training model 348 with parameters: {'max_depth': 150, 'min_samples_split': 2, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 348\n",
            "Training model 349 with parameters: {'max_depth': 150, 'min_samples_split': 2, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 349\n",
            "Training model 350 with parameters: {'max_depth': 150, 'min_samples_split': 2, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 350\n",
            "Training model 351 with parameters: {'max_depth': 150, 'min_samples_split': 3, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 351\n",
            "Training model 352 with parameters: {'max_depth': 150, 'min_samples_split': 3, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 352\n",
            "Training model 353 with parameters: {'max_depth': 150, 'min_samples_split': 3, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 353\n",
            "Training model 354 with parameters: {'max_depth': 150, 'min_samples_split': 3, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 354\n",
            "Training model 355 with parameters: {'max_depth': 150, 'min_samples_split': 3, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 355\n",
            "Training model 356 with parameters: {'max_depth': 150, 'min_samples_split': 3, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 356\n",
            "Training model 357 with parameters: {'max_depth': 150, 'min_samples_split': 3, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 357\n",
            "Training model 358 with parameters: {'max_depth': 150, 'min_samples_split': 4, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 358\n",
            "Training model 359 with parameters: {'max_depth': 150, 'min_samples_split': 4, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 359\n",
            "Training model 360 with parameters: {'max_depth': 150, 'min_samples_split': 4, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 360\n",
            "Training model 361 with parameters: {'max_depth': 150, 'min_samples_split': 4, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 361\n",
            "Training model 362 with parameters: {'max_depth': 150, 'min_samples_split': 4, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 362\n",
            "Training model 363 with parameters: {'max_depth': 150, 'min_samples_split': 4, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 363\n",
            "Training model 364 with parameters: {'max_depth': 150, 'min_samples_split': 4, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 364\n",
            "Training model 365 with parameters: {'max_depth': 150, 'min_samples_split': 5, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.08271636 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07072503 -1.14592184]\n",
            "Results saved for model 365\n",
            "Training model 366 with parameters: {'max_depth': 150, 'min_samples_split': 5, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 366\n",
            "Training model 367 with parameters: {'max_depth': 150, 'min_samples_split': 5, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 367\n",
            "Training model 368 with parameters: {'max_depth': 150, 'min_samples_split': 5, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 368\n",
            "Training model 369 with parameters: {'max_depth': 150, 'min_samples_split': 5, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 369\n",
            "Training model 370 with parameters: {'max_depth': 150, 'min_samples_split': 5, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 370\n",
            "Training model 371 with parameters: {'max_depth': 150, 'min_samples_split': 5, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 371\n",
            "Training model 372 with parameters: {'max_depth': 150, 'min_samples_split': 6, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.08271636 -7.41066696 -7.65700311 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.29404336 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.07280293 -8.74714413 -5.07072503 -1.12516302]\n",
            "Results saved for model 372\n",
            "Training model 373 with parameters: {'max_depth': 150, 'min_samples_split': 6, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 373\n",
            "Training model 374 with parameters: {'max_depth': 150, 'min_samples_split': 6, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 374\n",
            "Training model 375 with parameters: {'max_depth': 150, 'min_samples_split': 6, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 375\n",
            "Training model 376 with parameters: {'max_depth': 150, 'min_samples_split': 6, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 376\n",
            "Training model 377 with parameters: {'max_depth': 150, 'min_samples_split': 6, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 377\n",
            "Training model 378 with parameters: {'max_depth': 150, 'min_samples_split': 6, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 378\n",
            "Training model 379 with parameters: {'max_depth': 150, 'min_samples_split': 7, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.01922954 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -7.01922954 -7.29404336 -2.63252012 -1.03961234]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.74714413 -5.07072503 -1.12516302]\n",
            "Results saved for model 379\n",
            "Training model 380 with parameters: {'max_depth': 150, 'min_samples_split': 7, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.01922954 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -7.01922954 -7.29404336 -1.01310533 -1.03753959]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 380\n",
            "Training model 381 with parameters: {'max_depth': 150, 'min_samples_split': 7, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 381\n",
            "Training model 382 with parameters: {'max_depth': 150, 'min_samples_split': 7, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 382\n",
            "Training model 383 with parameters: {'max_depth': 150, 'min_samples_split': 7, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 383\n",
            "Training model 384 with parameters: {'max_depth': 150, 'min_samples_split': 7, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 384\n",
            "Training model 385 with parameters: {'max_depth': 150, 'min_samples_split': 7, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 385\n",
            "Training model 386 with parameters: {'max_depth': 150, 'min_samples_split': 8, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.01922954 -7.4774067  -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -7.01922954 -7.29404336 -2.63252012 -1.03961234]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.74714413 -4.43396504 -1.12516302]\n",
            "Results saved for model 386\n",
            "Training model 387 with parameters: {'max_depth': 150, 'min_samples_split': 8, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.01922954 -7.4774067  -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -7.01922954 -7.29404336 -1.01310533 -1.03753959]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.79099878 -4.43396504 -1.12516302]\n",
            "Results saved for model 387\n",
            "Training model 388 with parameters: {'max_depth': 150, 'min_samples_split': 8, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 388\n",
            "Training model 389 with parameters: {'max_depth': 150, 'min_samples_split': 8, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 389\n",
            "Training model 390 with parameters: {'max_depth': 150, 'min_samples_split': 8, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 390\n",
            "Training model 391 with parameters: {'max_depth': 150, 'min_samples_split': 8, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 391\n",
            "Training model 392 with parameters: {'max_depth': 150, 'min_samples_split': 8, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 392\n",
            "Training model 393 with parameters: {'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 393\n",
            "Training model 394 with parameters: {'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 394\n",
            "Training model 395 with parameters: {'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 395\n",
            "Training model 396 with parameters: {'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 396\n",
            "Training model 397 with parameters: {'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 397\n",
            "Training model 398 with parameters: {'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 398\n",
            "Training model 399 with parameters: {'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 399\n",
            "Training model 400 with parameters: {'max_depth': 300, 'min_samples_split': 3, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 400\n",
            "Training model 401 with parameters: {'max_depth': 300, 'min_samples_split': 3, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 401\n",
            "Training model 402 with parameters: {'max_depth': 300, 'min_samples_split': 3, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 402\n",
            "Training model 403 with parameters: {'max_depth': 300, 'min_samples_split': 3, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 403\n",
            "Training model 404 with parameters: {'max_depth': 300, 'min_samples_split': 3, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 404\n",
            "Training model 405 with parameters: {'max_depth': 300, 'min_samples_split': 3, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 405\n",
            "Training model 406 with parameters: {'max_depth': 300, 'min_samples_split': 3, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 406\n",
            "Training model 407 with parameters: {'max_depth': 300, 'min_samples_split': 4, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.02994276 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07755151 -1.14592184]\n",
            "Results saved for model 407\n",
            "Training model 408 with parameters: {'max_depth': 300, 'min_samples_split': 4, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 408\n",
            "Training model 409 with parameters: {'max_depth': 300, 'min_samples_split': 4, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 409\n",
            "Training model 410 with parameters: {'max_depth': 300, 'min_samples_split': 4, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 410\n",
            "Training model 411 with parameters: {'max_depth': 300, 'min_samples_split': 4, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 411\n",
            "Training model 412 with parameters: {'max_depth': 300, 'min_samples_split': 4, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 412\n",
            "Training model 413 with parameters: {'max_depth': 300, 'min_samples_split': 4, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 413\n",
            "Training model 414 with parameters: {'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.08271636 -7.41066696 -7.60676989 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.31074927 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.10129698 -8.74714413 -5.07072503 -1.14592184]\n",
            "Results saved for model 414\n",
            "Training model 415 with parameters: {'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 415\n",
            "Training model 416 with parameters: {'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 416\n",
            "Training model 417 with parameters: {'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 417\n",
            "Training model 418 with parameters: {'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 418\n",
            "Training model 419 with parameters: {'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 419\n",
            "Training model 420 with parameters: {'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 420\n",
            "Training model 421 with parameters: {'max_depth': 300, 'min_samples_split': 6, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.08271636 -7.41066696 -7.65700311 -5.58876231]\n",
            "Predictions on validation data: [-8.74714413 -6.8922559  -7.29404336 -2.63252012 -1.02541076]\n",
            "Predictions on testing data: [-6.8922559  -5.07280293 -8.74714413 -5.07072503 -1.12516302]\n",
            "Results saved for model 421\n",
            "Training model 422 with parameters: {'max_depth': 300, 'min_samples_split': 6, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.10559522 -7.41066696 -7.65700311 -5.60246059]\n",
            "Predictions on validation data: [-8.79099878 -6.93286386 -7.29404336 -0.71415587 -1.03753959]\n",
            "Predictions on testing data: [-6.93286386 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 422\n",
            "Training model 423 with parameters: {'max_depth': 300, 'min_samples_split': 6, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 423\n",
            "Training model 424 with parameters: {'max_depth': 300, 'min_samples_split': 6, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 424\n",
            "Training model 425 with parameters: {'max_depth': 300, 'min_samples_split': 6, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 425\n",
            "Training model 426 with parameters: {'max_depth': 300, 'min_samples_split': 6, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 426\n",
            "Training model 427 with parameters: {'max_depth': 300, 'min_samples_split': 6, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 427\n",
            "Training model 428 with parameters: {'max_depth': 300, 'min_samples_split': 7, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.01922954 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -7.01922954 -7.29404336 -2.63252012 -1.03961234]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.74714413 -5.07072503 -1.12516302]\n",
            "Results saved for model 428\n",
            "Training model 429 with parameters: {'max_depth': 300, 'min_samples_split': 7, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.01922954 -7.41066696 -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -7.01922954 -7.29404336 -1.01310533 -1.03753959]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.79099878 -5.07072503 -1.12516302]\n",
            "Results saved for model 429\n",
            "Training model 430 with parameters: {'max_depth': 300, 'min_samples_split': 7, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 430\n",
            "Training model 431 with parameters: {'max_depth': 300, 'min_samples_split': 7, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 431\n",
            "Training model 432 with parameters: {'max_depth': 300, 'min_samples_split': 7, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 432\n",
            "Training model 433 with parameters: {'max_depth': 300, 'min_samples_split': 7, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 433\n",
            "Training model 434 with parameters: {'max_depth': 300, 'min_samples_split': 7, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 434\n",
            "Training model 435 with parameters: {'max_depth': 300, 'min_samples_split': 8, 'min_samples_leaf': 2}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.69897    -7.01922954 -7.4774067  -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.74714413 -7.01922954 -7.29404336 -2.63252012 -1.03961234]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.74714413 -4.43396504 -1.12516302]\n",
            "Results saved for model 435\n",
            "Training model 436 with parameters: {'max_depth': 300, 'min_samples_split': 8, 'min_samples_leaf': 3}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.01922954 -7.4774067  -7.65700311 -5.63468116]\n",
            "Predictions on validation data: [-8.79099878 -7.01922954 -7.29404336 -1.01310533 -1.03753959]\n",
            "Predictions on testing data: [-7.01922954 -5.07280293 -8.79099878 -4.43396504 -1.12516302]\n",
            "Results saved for model 436\n",
            "Training model 437 with parameters: {'max_depth': 300, 'min_samples_split': 8, 'min_samples_leaf': 4}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-7.98524816 -7.08271636 -7.4774067  -7.83952498 -5.63468116]\n",
            "Predictions on validation data: [-9.2615493  -6.70242292 -7.29404336 -1.01310533 -1.03107805]\n",
            "Predictions on testing data: [-6.70242292 -5.07280293 -8.76681591 -4.43396504 -1.12516302]\n",
            "Results saved for model 437\n",
            "Training model 438 with parameters: {'max_depth': 300, 'min_samples_split': 8, 'min_samples_leaf': 5}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -7.0468606  -7.4774067  -7.80079829 -5.63468116]\n",
            "Predictions on validation data: [-9.16397102 -6.55383319 -7.29404336 -1.01310533 -1.07606306]\n",
            "Predictions on testing data: [-6.55383319 -5.10577195 -9.16397102 -4.43396504 -1.12516302]\n",
            "Results saved for model 438\n",
            "Training model 439 with parameters: {'max_depth': 300, 'min_samples_split': 8, 'min_samples_leaf': 6}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.63468116]\n",
            "Predictions on validation data: [-9.06664989 -6.8003469  -7.2210835  -1.01310533 -1.04055229]\n",
            "Predictions on testing data: [-6.8003469  -5.07187942 -9.06664989 -5.07187942 -1.11254432]\n",
            "Results saved for model 439\n",
            "Training model 440 with parameters: {'max_depth': 300, 'min_samples_split': 8, 'min_samples_leaf': 7}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.4774067  -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.72117004 -6.8003469  -7.2210835  -1.54059511 -1.06938832]\n",
            "Predictions on testing data: [-6.8003469  -5.1109948  -8.72117004 -4.40487689 -1.10828408]\n",
            "Results saved for model 440\n",
            "Training model 441 with parameters: {'max_depth': 300, 'min_samples_split': 8, 'min_samples_leaf': 8}\n",
            "Training with x_train_final shape: (40712, 32), y_train_final shape: (40712,)\n",
            "Predictions on training data: [-8.03886158 -6.8003469  -7.45568631 -7.79827488 -5.7083975 ]\n",
            "Predictions on validation data: [-8.65581338 -6.8003469  -7.45568631 -1.618047   -1.07154523]\n",
            "Predictions on testing data: [-6.8003469  -4.78147311 -8.65581338 -4.78147311 -1.10769049]\n",
            "Results saved for model 441\n",
            "All results compiled and saved to /content/drive/My Drive/ML_Nuclear_Data/ML_Saving_Directory/All Rows_basic=1_protons/all_results_maxdepth(10-30-50-70-76-82-88-150-300)_mss(2-3-4-5-6-7-8)_msl(2-3-4-5-6-7-8).csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      id  max_depth  mss  msl       normalizer  train_mae  train_mse  \\\n",
              "0      1         10    2    2  standard_scaler   0.403760   0.362229   \n",
              "1      2         10    2    3  standard_scaler   0.405240   0.364699   \n",
              "2      3         10    2    4  standard_scaler   0.408230   0.388624   \n",
              "3      4         10    2    5  standard_scaler   0.409920   0.394071   \n",
              "4      5         10    2    6  standard_scaler   0.412280   0.399730   \n",
              "..   ...        ...  ...  ...              ...        ...        ...   \n",
              "436  437        300    8    4  standard_scaler   0.223882   0.188564   \n",
              "437  438        300    8    5  standard_scaler   0.238108   0.206742   \n",
              "438  439        300    8    6  standard_scaler   0.250575   0.222266   \n",
              "439  440        300    8    7  standard_scaler   0.258206   0.231095   \n",
              "440  441        300    8    8  standard_scaler   0.267259   0.242286   \n",
              "\n",
              "     train_evs  train_r2   val_mae   val_mse   val_evs    val_r2  test_mae  \\\n",
              "0     0.762545  0.762545  0.416117  0.397320  0.756522  0.756522  0.419783   \n",
              "1     0.760538  0.760538  0.417332  0.399287  0.754530  0.754530  0.419730   \n",
              "2     0.740756  0.740756  0.421725  0.467092  0.690291  0.690288  0.426855   \n",
              "3     0.736164  0.736164  0.422404  0.456612  0.702775  0.702772  0.427373   \n",
              "4     0.731358  0.731358  0.423550  0.459242  0.699787  0.699785  0.427153   \n",
              "..         ...       ...       ...       ...       ...       ...       ...   \n",
              "436   0.889023  0.889023  0.317004  0.378233  0.777132  0.777125  0.310283   \n",
              "437   0.877009  0.877009  0.318297  0.365056  0.786963  0.786959  0.316516   \n",
              "438   0.866541  0.866541  0.323275  0.369674  0.782139  0.782130  0.317688   \n",
              "439   0.860500  0.860500  0.324791  0.367651  0.781934  0.781921  0.320421   \n",
              "440   0.852750  0.852750  0.330501  0.382035  0.772959  0.772936  0.322280   \n",
              "\n",
              "     test_mse  test_evs   test_r2  \\\n",
              "0    0.405533  0.725844  0.725600   \n",
              "1    0.406765  0.723634  0.723391   \n",
              "2    0.512466  0.689442  0.689360   \n",
              "3    0.472528  0.698847  0.698689   \n",
              "4    0.471631  0.698049  0.697890   \n",
              "..        ...       ...       ...   \n",
              "436  0.411734  0.776748  0.776670   \n",
              "437  0.375667  0.785271  0.785199   \n",
              "438  0.373172  0.785968  0.785914   \n",
              "439  0.373700  0.783791  0.783706   \n",
              "440  0.371033  0.783065  0.782946   \n",
              "\n",
              "                                            model_path  \\\n",
              "0    /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...   \n",
              "1    /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...   \n",
              "2    /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...   \n",
              "3    /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...   \n",
              "4    /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...   \n",
              "..                                                 ...   \n",
              "436  /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...   \n",
              "437  /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...   \n",
              "438  /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...   \n",
              "439  /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...   \n",
              "440  /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...   \n",
              "\n",
              "                                           scaler_path  \n",
              "0    /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...  \n",
              "1    /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...  \n",
              "2    /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...  \n",
              "3    /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...  \n",
              "4    /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...  \n",
              "..                                                 ...  \n",
              "436  /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...  \n",
              "437  /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...  \n",
              "438  /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...  \n",
              "439  /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...  \n",
              "440  /content/drive/My Drive/ML_Nuclear_Data/ML_Sav...  \n",
              "\n",
              "[441 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b21175f-33e1-494c-8b5c-502e37c895f0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>mss</th>\n",
              "      <th>msl</th>\n",
              "      <th>normalizer</th>\n",
              "      <th>train_mae</th>\n",
              "      <th>train_mse</th>\n",
              "      <th>train_evs</th>\n",
              "      <th>train_r2</th>\n",
              "      <th>val_mae</th>\n",
              "      <th>val_mse</th>\n",
              "      <th>val_evs</th>\n",
              "      <th>val_r2</th>\n",
              "      <th>test_mae</th>\n",
              "      <th>test_mse</th>\n",
              "      <th>test_evs</th>\n",
              "      <th>test_r2</th>\n",
              "      <th>model_path</th>\n",
              "      <th>scaler_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>standard_scaler</td>\n",
              "      <td>0.403760</td>\n",
              "      <td>0.362229</td>\n",
              "      <td>0.762545</td>\n",
              "      <td>0.762545</td>\n",
              "      <td>0.416117</td>\n",
              "      <td>0.397320</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.419783</td>\n",
              "      <td>0.405533</td>\n",
              "      <td>0.725844</td>\n",
              "      <td>0.725600</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>standard_scaler</td>\n",
              "      <td>0.405240</td>\n",
              "      <td>0.364699</td>\n",
              "      <td>0.760538</td>\n",
              "      <td>0.760538</td>\n",
              "      <td>0.417332</td>\n",
              "      <td>0.399287</td>\n",
              "      <td>0.754530</td>\n",
              "      <td>0.754530</td>\n",
              "      <td>0.419730</td>\n",
              "      <td>0.406765</td>\n",
              "      <td>0.723634</td>\n",
              "      <td>0.723391</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>standard_scaler</td>\n",
              "      <td>0.408230</td>\n",
              "      <td>0.388624</td>\n",
              "      <td>0.740756</td>\n",
              "      <td>0.740756</td>\n",
              "      <td>0.421725</td>\n",
              "      <td>0.467092</td>\n",
              "      <td>0.690291</td>\n",
              "      <td>0.690288</td>\n",
              "      <td>0.426855</td>\n",
              "      <td>0.512466</td>\n",
              "      <td>0.689442</td>\n",
              "      <td>0.689360</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>standard_scaler</td>\n",
              "      <td>0.409920</td>\n",
              "      <td>0.394071</td>\n",
              "      <td>0.736164</td>\n",
              "      <td>0.736164</td>\n",
              "      <td>0.422404</td>\n",
              "      <td>0.456612</td>\n",
              "      <td>0.702775</td>\n",
              "      <td>0.702772</td>\n",
              "      <td>0.427373</td>\n",
              "      <td>0.472528</td>\n",
              "      <td>0.698847</td>\n",
              "      <td>0.698689</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>standard_scaler</td>\n",
              "      <td>0.412280</td>\n",
              "      <td>0.399730</td>\n",
              "      <td>0.731358</td>\n",
              "      <td>0.731358</td>\n",
              "      <td>0.423550</td>\n",
              "      <td>0.459242</td>\n",
              "      <td>0.699787</td>\n",
              "      <td>0.699785</td>\n",
              "      <td>0.427153</td>\n",
              "      <td>0.471631</td>\n",
              "      <td>0.698049</td>\n",
              "      <td>0.697890</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>437</td>\n",
              "      <td>300</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>standard_scaler</td>\n",
              "      <td>0.223882</td>\n",
              "      <td>0.188564</td>\n",
              "      <td>0.889023</td>\n",
              "      <td>0.889023</td>\n",
              "      <td>0.317004</td>\n",
              "      <td>0.378233</td>\n",
              "      <td>0.777132</td>\n",
              "      <td>0.777125</td>\n",
              "      <td>0.310283</td>\n",
              "      <td>0.411734</td>\n",
              "      <td>0.776748</td>\n",
              "      <td>0.776670</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>438</td>\n",
              "      <td>300</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>standard_scaler</td>\n",
              "      <td>0.238108</td>\n",
              "      <td>0.206742</td>\n",
              "      <td>0.877009</td>\n",
              "      <td>0.877009</td>\n",
              "      <td>0.318297</td>\n",
              "      <td>0.365056</td>\n",
              "      <td>0.786963</td>\n",
              "      <td>0.786959</td>\n",
              "      <td>0.316516</td>\n",
              "      <td>0.375667</td>\n",
              "      <td>0.785271</td>\n",
              "      <td>0.785199</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>439</td>\n",
              "      <td>300</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>standard_scaler</td>\n",
              "      <td>0.250575</td>\n",
              "      <td>0.222266</td>\n",
              "      <td>0.866541</td>\n",
              "      <td>0.866541</td>\n",
              "      <td>0.323275</td>\n",
              "      <td>0.369674</td>\n",
              "      <td>0.782139</td>\n",
              "      <td>0.782130</td>\n",
              "      <td>0.317688</td>\n",
              "      <td>0.373172</td>\n",
              "      <td>0.785968</td>\n",
              "      <td>0.785914</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>440</td>\n",
              "      <td>300</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>standard_scaler</td>\n",
              "      <td>0.258206</td>\n",
              "      <td>0.231095</td>\n",
              "      <td>0.860500</td>\n",
              "      <td>0.860500</td>\n",
              "      <td>0.324791</td>\n",
              "      <td>0.367651</td>\n",
              "      <td>0.781934</td>\n",
              "      <td>0.781921</td>\n",
              "      <td>0.320421</td>\n",
              "      <td>0.373700</td>\n",
              "      <td>0.783791</td>\n",
              "      <td>0.783706</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>441</td>\n",
              "      <td>300</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>standard_scaler</td>\n",
              "      <td>0.267259</td>\n",
              "      <td>0.242286</td>\n",
              "      <td>0.852750</td>\n",
              "      <td>0.852750</td>\n",
              "      <td>0.330501</td>\n",
              "      <td>0.382035</td>\n",
              "      <td>0.772959</td>\n",
              "      <td>0.772936</td>\n",
              "      <td>0.322280</td>\n",
              "      <td>0.371033</td>\n",
              "      <td>0.783065</td>\n",
              "      <td>0.782946</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "      <td>/content/drive/My Drive/ML_Nuclear_Data/ML_Sav...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>441 rows × 19 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b21175f-33e1-494c-8b5c-502e37c895f0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2b21175f-33e1-494c-8b5c-502e37c895f0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2b21175f-33e1-494c-8b5c-502e37c895f0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b4c99780-bf23-47ff-abf2-a1972afba75e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b4c99780-bf23-47ff-abf2-a1972afba75e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b4c99780-bf23-47ff-abf2-a1972afba75e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_894faf32-b27c-416d-856e-168d0faffaa7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_894faf32-b27c-416d-856e-168d0faffaa7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 441,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 127,\n        \"min\": 1,\n        \"max\": 441,\n        \"num_unique_values\": 441,\n        \"samples\": [\n          79,\n          440,\n          153\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_depth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 81,\n        \"min\": 10,\n        \"max\": 300,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          150,\n          30,\n          82\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 8,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2,\n          3,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"msl\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 8,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2,\n          3,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"normalizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"standard_scaler\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_mae\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0613885904842678,\n        \"min\": 0.17783738728697332,\n        \"max\": 0.4146408182931984,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          0.4037598992095308\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_mse\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07069219792906266,\n        \"min\": 0.12692513346408513,\n        \"max\": 0.4053982059195494,\n        \"num_unique_values\": 57,\n        \"samples\": [\n          0.3622288981198729\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_evs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05091442989167014,\n        \"min\": 0.7265064360057604,\n        \"max\": 0.9279149146793024,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          0.9210269164306849\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_r2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05091442989167014,\n        \"min\": 0.7265064360057603,\n        \"max\": 0.9279149146793024,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          0.7603664311940885\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_mae\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03249404826994958,\n        \"min\": 0.31112191072142803,\n        \"max\": 0.4263911273201064,\n        \"num_unique_values\": 389,\n        \"samples\": [\n          0.32313133530843313\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_mse\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.036482157683752924,\n        \"min\": 0.31172478029813255,\n        \"max\": 0.4678448239680922,\n        \"num_unique_values\": 388,\n        \"samples\": [\n          0.3692466547175007\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_evs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03339778390037232,\n        \"min\": 0.6902911720490935,\n        \"max\": 0.83053954380428,\n        \"num_unique_values\": 393,\n        \"samples\": [\n          0.7744360211767248\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_r2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03338522952609944,\n        \"min\": 0.6902878396254343,\n        \"max\": 0.8305109745958632,\n        \"num_unique_values\": 390,\n        \"samples\": [\n          0.6904497395889413\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_mae\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03598538342987693,\n        \"min\": 0.30021527649496405,\n        \"max\": 0.42874329297184005,\n        \"num_unique_values\": 396,\n        \"samples\": [\n          0.3108004273557678\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_mse\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04840124896137973,\n        \"min\": 0.30203556098345274,\n        \"max\": 0.5513055971084698,\n        \"num_unique_values\": 408,\n        \"samples\": [\n          0.37244683617249585\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_evs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.032421516533403714,\n        \"min\": 0.661262604705276,\n        \"max\": 0.8203373370462244,\n        \"num_unique_values\": 399,\n        \"samples\": [\n          0.7836931643068081\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_r2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.032428629820506594,\n        \"min\": 0.6611228225548116,\n        \"max\": 0.8201366263172104,\n        \"num_unique_values\": 401,\n        \"samples\": [\n          0.7829126589009354\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 441,\n        \"samples\": [\n          \"/content/drive/My Drive/ML_Nuclear_Data/ML_Saving_Directory/All Rows_basic=1_protons/dt_model_79_mss6_msl3_maxdepth30.joblib\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scaler_path\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"/content/drive/My Drive/ML_Nuclear_Data/ML_Saving_Directory/All Rows_basic=1_protons/scaler.pkl\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9sNbSxeLiGqY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}